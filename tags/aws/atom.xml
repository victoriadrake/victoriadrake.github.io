<feed xmlns="http://www.w3.org/2005/Atom"><title>Aws on victoria.dev</title><link href="https://victoria.dev/tags/aws/feed.xml" rel="self"/><link href="https://victoria.dev/tags/aws/"/><updated>2021-10-07T11:01:13+00:00</updated><id>https://victoria.dev/tags/aws/</id><author><name>Victoria Drake</name><email>hello@victoria.dev</email></author><generator>Hugo -- gohugo.io</generator><entry><title type="html">Set up a Pi-hole VPN on an AWS Lightsail instance</title><link href="https://victoria.dev/archive/set-up-a-pi-hole-vpn-on-an-aws-lightsail-instance/"/><id>https://victoria.dev/archive/set-up-a-pi-hole-vpn-on-an-aws-lightsail-instance/</id><author><name>Victoria Drake</name></author><published>2021-10-07T11:01:13+00:00</published><updated>2021-10-07T11:01:13+00:00</updated><content type="html"><![CDATA[<p>I&rsquo;ve written a fair bit in the past about the <a href="/tags/privacy">whys of online privacy</a>, and <a href="/tags/cybersecurity">a lot about staying safe online</a>. Chances are, if a search brought you here, you&rsquo;re well-past why. Let&rsquo;s go straight on to how.</p>
<p>This guide will walk you through setting up <a href="https://pi-hole.net/">Pi-hole</a> on an <a href="https://aws.amazon.com/lightsail/">AWS Lightsail</a> instance that acts as your VPN thanks to <a href="https://openvpn.net/">OpenVPN</a>. It&rsquo;s a more succinct version of the <a href="https://docs.pi-hole.net/guides/vpn/openvpn/overview/">official Pi-hole docs for OpenVPN</a>, made specifically for Lightsail with a few tips and tricks added in, because you deserve it.</p>
<h2 id="create-and-connect-to-a-lightsail-instance">Create and connect to a Lightsail instance</h2>
<ol>
<li>
<p>Log in or sign up to AWS and <a href="https://lightsail.aws.amazon.com/ls/webapp/home/instances">create a Lightsail Instance</a>.</p>
</li>
<li>
<p>Under <strong>Select a platform</strong>, choose <strong>Linux/Unix</strong>.</p>
</li>
<li>
<p>Under <strong>Select a blueprint</strong>, choose the <strong>OS Only</strong> button.</p>
</li>
<li>
<p>Select the latest <a href="https://docs.pi-hole.net/main/prerequisites/#supported-operating-systems">officially supported Ubuntu server</a>.</p>
</li>
<li>
<p>You can save a tidbit of effort by putting the following into the <strong>Launch script</strong> box:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># Update installed packages</span>
</span></span><span style="display:flex;"><span>sudo apt-get update
</span></span><span style="display:flex;"><span>sudo apt-get upgrade -y
</span></span></code></pre></div></li>
<li>
<p>Create a new SSH key for this server and ensure you download the <code>.pem</code>.</p>
</li>
<li>
<p>Choose your plan. The $3.50 USD instance is sufficient.</p>
</li>
<li>
<p>Give it a name then click <strong>Create instance</strong>.</p>
</li>
<li>
<p>Stare eagerly at the page until the instance status is <strong>Running</strong>, then go to the <strong>Networking</strong> tab.</p>
</li>
<li>
<p>Create a <a href="https://lightsail.aws.amazon.com/ls/docs/en_us/articles/understanding-static-ip-addresses-in-amazon-lightsail">Static IP</a> and attach it to your new instance. Remember that static IP addresses are free only while attached to an instance.</p>
</li>
<li>
<p>Click on your instance name to return to its dashboard. Go back to the <strong>Networking</strong> tab. It&rsquo;ll look a bit different now.</p>
</li>
<li>
<p>Under <strong>IPv6 networking</strong>, click the toggle to turn it off (unless you know what you are doing and you want IPv6 for some reason. Most of y&rsquo;all don&rsquo;t need it).</p>
</li>
<li>
<p>Under <strong>IPv4 Firewall</strong>, delete the rule for <code>HTTP</code>.</p>
</li>
<li>
<p>Click <strong>Add rule</strong>. In the <strong>Application</strong> dropdown, choose <strong>Custom</strong>.</p>
<ul>
<li>For <strong>Protocol</strong>, choose <strong>UDP</strong>.</li>
<li>In the <strong>Port or range</strong> input, enter a UDP port for the OpenVPN server to run on. (It&rsquo;s typically <code>1194</code>, which you can choose to use, but you might like a different number for security purposes. Port range is <code>0-65535</code>.)</li>
</ul>
</li>
<li>
<p>Connect using SSH and your new key pair, either <a href="https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-ssh-using-terminal">in your terminal</a> or on the <strong>Connect</strong> tab with the <a href="https://lightsail.aws.amazon.com/ls/docs/en_us/articles/lightsail-how-to-connect-to-your-instance-virtual-private-server">browser-based client</a>.</p>
</li>
</ol>
<h2 id="install-openvpn-on-your-server">Install OpenVPN on your server</h2>
<p>After connecting to your server using SSH, install OpenVPN on your server.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># Download OpenVPN</span>
</span></span><span style="display:flex;"><span>wget https://git.io/vpn -O openvpn-install.sh
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">755</span> openvpn-install.sh
</span></span><span style="display:flex;"><span>sudo ./openvpn-install.sh
</span></span></code></pre></div><p>You&rsquo;ll see:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>Welcome to this OpenVPN road warrior installer!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>This server is behind NAT. What is the public IPv4 address or hostname?
</span></span><span style="display:flex;"><span>Public IPv4 address / hostname [x.xx.xxx.xxx]:
</span></span></code></pre></div><p>&hellip;where the default option is your static IP that you set up earlier. Hit return to accept this. Then:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>Which protocol should OpenVPN use?
</span></span><span style="display:flex;"><span>    1) UDP (recommended)
</span></span><span style="display:flex;"><span>    2) TCP
</span></span><span style="display:flex;"><span>Protocol [1]: 1
</span></span></code></pre></div><p>Choose <code>1</code> or hit return. Then:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>What port should OpenVPN listen to?
</span></span><span style="display:flex;"><span>Port [1194]: #####
</span></span></code></pre></div><p>Enter the UDP port number you chose earlier. Then:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>Select a DNS server for the clients:
</span></span><span style="display:flex;"><span>    1) Current system resolvers
</span></span><span style="display:flex;"><span>    2) Google
</span></span><span style="display:flex;"><span>    3) 1.1.1.1
</span></span><span style="display:flex;"><span>    4) OpenDNS
</span></span><span style="display:flex;"><span>    5) Quad9
</span></span><span style="display:flex;"><span>    6) AdGuard
</span></span><span style="display:flex;"><span>DNS server [1]: 1
</span></span></code></pre></div><p>Choose <code>1</code> or hit return. Then:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-txt" data-lang="txt"><span style="display:flex;"><span>Enter a name for the first client:
</span></span><span style="display:flex;"><span>Name [client]: pihole
</span></span></code></pre></div><p>The Pi-hole will be the client. Name it as you like then <code>Press any key to continue...</code></p>
<p>OpenVPN will set itself up. Confirm that <code>tun0</code> has the interface address <code>10.8.0.1/24</code> with the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ip addr show tun0
</span></span></code></pre></div><p>This ensures that the Pi-hole will be set up properly. Now, about that:</p>
<h2 id="install-and-configure-pi-hole">Install and configure Pi-hole</h2>
<p>On your Lightsail instance, install Pi-hole.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># Download and install Pi-hole</span>
</span></span><span style="display:flex;"><span>curl -sSL https://install.pi-hole.net | bash
</span></span></code></pre></div><p>This runs the Pi-hole automated installer. You&rsquo;ll see some prompts which you can answer using the enter key, arrow keys, tab, and space bar for selecting an option.</p>
<p>The important things:</p>
<ol>
<li>When you see <strong>Choose An Interface</strong>, ensure you pick <code>tun0</code>. It isn&rsquo;t the default selection.</li>
<li>You&rsquo;ll need to set the <strong>IPv4 address</strong> to the interface address you viewed previously using the <code>ip addr</code> command: <code>10.8.0.1/24</code>. This ensures the Pi-hole uses the VPN.</li>
</ol>
<blockquote>
<p><em>At time of writing,</em> the second item above wasn&rsquo;t presented as an option in the automated installer. After the Pi-hole installer finishes, manually change the IP address by editing the configuration file:</p>
<p><code>&gt; sudo vim /etc/pihole/setupVars.conf</code></p>
<p>Change the <code>IPV4_ADDRESS</code> to <code>10.8.0.1/24</code> and save the file. Restart the Pi-hole with: <code>pihole restartdns</code>.</p></blockquote>
<p>If you mess up, you can redo the configuration with <code>pihole reconfigure</code>.</p>
<p>Finally, you&rsquo;ll configure the VPN to use the Pi-hole.</p>
<h2 id="configure-openvpn">Configure OpenVPN</h2>
<p>Confirm the address of the <code>tun0</code> interface with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ip a | grep -C <span style="color:#ae81ff">1</span> <span style="color:#e6db74">&#39;tun0&#39;</span>
</span></span></code></pre></div><p>You should see: <code>inet 10.8.0.1/24</code> in there.</p>
<p>Edit the OpenVPN config file with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo vim /etc/openvpn/server/server.conf
</span></span></code></pre></div><p>Change the line that starts with <code>push &quot;dhcp-option</code>&hellip; to use the Pi-hole&rsquo;s IP address that you confirmed above:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-vim" data-lang="vim"><span style="display:flex;"><span><span style="color:#a6e22e">push</span> <span style="color:#e6db74">&#34;dhcp-option DNS 10.8.0.1&#34;</span>
</span></span></code></pre></div><p>If any other lines start with <code>push &quot;dhcp-option</code>&hellip;, comment those out.</p>
<p>If you want to log OpenVPN traffic, add these lines to the end of the file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-vim" data-lang="vim"><span style="display:flex;"><span><span style="color:#a6e22e">log</span> <span style="color:#e6db74">/var/</span><span style="color:#a6e22e">log</span>/<span style="color:#a6e22e">openvpn</span>.<span style="color:#a6e22e">log</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">verb</span> <span style="color:#ae81ff">3</span>
</span></span></code></pre></div><p>Save the config. If you forgot to open Vim with <code>sudo</code>, use the <code>tee</code> trick: <code>:w !sudo tee %</code>, then <code>O</code>, then <code>:q!</code>.</p>
<p>Restart OpenVPN with <code>sudo systemctl restart openvpn-server@server</code>.</p>
<h3 id="configure-firewall">Configure firewall</h3>
<p>Run the following to control traffic to the server <a href="https://docs.pi-hole.net/guides/vpn/openvpn/firewall/">as described here</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo iptables -I INPUT -i tun0 -j ACCEPT
</span></span><span style="display:flex;"><span>sudo iptables -A INPUT -i tun0 -p tcp --destination-port <span style="color:#ae81ff">53</span> -j ACCEPT
</span></span><span style="display:flex;"><span>sudo iptables -A INPUT -i tun0 -p udp --destination-port <span style="color:#ae81ff">53</span> -j ACCEPT
</span></span><span style="display:flex;"><span>sudo iptables -A INPUT -i tun0 -p tcp --destination-port <span style="color:#ae81ff">80</span> -j ACCEPT
</span></span><span style="display:flex;"><span>sudo iptables -A INPUT -p tcp --destination-port <span style="color:#ae81ff">22</span> -j ACCEPT
</span></span><span style="display:flex;"><span>sudo iptables -A INPUT -p tcp --destination-port <span style="color:#ae81ff">1194</span> -j ACCEPT
</span></span><span style="display:flex;"><span>sudo iptables -A INPUT -p udp --destination-port <span style="color:#ae81ff">1194</span> -j ACCEPT
</span></span><span style="display:flex;"><span>sudo iptables -I INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
</span></span><span style="display:flex;"><span>sudo iptables -I INPUT -i lo -j ACCEPT
</span></span><span style="display:flex;"><span>sudo iptables -P INPUT DROP
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Optionally, also block HTTPS advertisements while you&#39;re here.</span>
</span></span><span style="display:flex;"><span>sudo iptables -A INPUT -p udp --dport <span style="color:#ae81ff">80</span> -j REJECT --reject-with icmp-port-unreachable
</span></span><span style="display:flex;"><span>sudo iptables -A INPUT -p tcp --dport <span style="color:#ae81ff">443</span> -j REJECT --reject-with tcp-reset
</span></span><span style="display:flex;"><span>sudo iptables -A INPUT -p udp --dport <span style="color:#ae81ff">443</span> -j REJECT --reject-with icmp-port-unreachable
</span></span></code></pre></div><p>You can review the results with <code>sudo iptables -L --line-numbers</code>.</p>
<p><strong>These are only stored in memory</strong> before you save them, so test out your set up on your client now to see if it all works as expected.</p>
<h3 id="test-your-client-connection">Test your client connection</h3>
<p>To test your configuration, try adding a client (the phone or computer that will connect to the VPN).</p>
<ol>
<li>Run the OpenVPN script again: <code>sudo ./openvpn-install.sh</code> and choose <strong>1) Add a new client</strong>. Give it a name; you may find it helps to name it by the device, e.g. &ldquo;phone&rdquo;. This creates a file that ends in <code>.ovpn</code>. You need to place this file on your client to use it.</li>
<li>Install the appropriate <a href="https://duckduckgo.com/?q=OpenVPN+App">OpenVPN app</a> for your device.</li>
<li>Transfer the <code>.ovpn</code> file you just obtained to the device if you haven&rsquo;t already. (See <a href="#future-tasks">future tasks</a> for a way to copy the file to your host machine.) Follow instructions in your app (try under <strong>FAQ</strong>) for importing the <code>.ovpn</code> file and activating the VPN.</li>
<li>Ensure it seems to connect properly. If you <a href="https://duckduckgo.com/?t=ffab&amp;q=what's+my+ip">go to DuckDuckGo.com and search for &ldquo;What&rsquo;s my IP&rdquo;</a>, you should see the location of your Lightsail instance. For a more in-depth test, <a href="https://browserleaks.com/ip">check for DNS leaks at BrowserLeaks.com</a>.</li>
</ol>
<p>Try browsing for a while. You can also view the Pi-hole dashboard by visiting <code>http://pi.hole/admin/</code> on this device.</p>
<p>If everything seems all right, go on to saving the configuration on your instance.</p>
<h3 id="save-iptables">Save <code>iptables</code></h3>
<p>Save the <code>iptables</code> you created earlier using the <code>tee</code> command to achieve the second permission.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo iptables-save | sudo tee /etc/pihole/rules.v4
</span></span></code></pre></div><p>You&rsquo;re finished with configuration on your Lightsail instance. If you wish to disconnect now, you can just type <code>exit</code>.</p>
<h2 id="future-tasks">Future tasks</h2>
<p>You&rsquo;re done with the set up! You now have your very own personal VPN with a Pi-hole keeping you safe from nasty trackers. Here are some references for operations you might like to come back to in the future:</p>
<ul>
<li>Reconnect to your Lightsail instance with SSH:
<ul>
<li><code>ssh -i /path/to/private-key.pem ubuntu@public-ip-address</code></li>
</ul>
</li>
<li>Set a password for the web interface dashboard:
<ul>
<li><code>pihole -a -p</code></li>
</ul>
</li>
<li>Access the web interface dashboard:
<ul>
<li>Connect to the VPN, then visit <code>http://pi.hole/admin/</code></li>
</ul>
</li>
<li>Update the Pi-hole:
<ul>
<li><code>pihole -up</code></li>
</ul>
</li>
<li>Add a new client (<a href="https://docs.pi-hole.net/guides/vpn/openvpn/clients/">for iOS, Linux, or Windows</a>, or <a href="https://docs.pi-hole.net/guides/vpn/openvpn/android-client/">for Android</a>)</li>
<li>Copy the <code>.ovpn</code> file for a client to your host machine (run on the host machine):
<ul>
<li><code>ssh -i /path/to/private-key.pem ubuntu@public-ip-address 'sudo cat /path/on/lightsail/client.ovpn' &gt; /path/on/host/client.ovpn</code></li>
</ul>
</li>
<li>Beef up that block list! Here&rsquo;s my favorite resource for updating your Pi-hole <a href="https://docs.pi-hole.net/database/gravity/#adlist-table-adlist">adlist table</a>: <a href="https://firebog.net/">The Big Blocklist Collection</a></li>
</ul>
<p>Enjoy your new, more secure and peaceful Internet! If you found this guide helpful, please share it with someone else.</p>
]]></content></entry><entry><title type="html">Create a self-hosted chat service with your own Matrix server</title><link href="https://victoria.dev/archive/create-a-self-hosted-chat-service-with-your-own-matrix-server/"/><id>https://victoria.dev/archive/create-a-self-hosted-chat-service-with-your-own-matrix-server/</id><author><name>Victoria Drake</name></author><published>2021-02-15T01:38:07-05:00</published><updated>2021-02-15T01:38:07-05:00</updated><content type="html"><![CDATA[<p><a href="https://matrix.org/docs/guides/introduction">Matrix</a> is an open standard for decentralized real-time communication. The <a href="https://matrix.org/docs/spec/">specification</a> is production-ready and <a href="https://matrix.org/bridges/">bridges</a> to tons of silo products like Slack, Gitter, Telegram, Discord, and even Facebook Messenger. This lets you use Matrix to link together disjoint communities in one place, or create an alternative communication method that works with, but is independent of, communication silos.</p>
<p>You can create your own self-hosted Matrix chat for as little as $3.50 USD per month on an <a href="https://aws.amazon.com/lightsail/">AWS Lightsail</a> instance. Your homeserver can federate with other Matrix servers, giving you a reliable and fault-tolerant means of communication.</p>
<p>Matrix is most widely installed via its <a href="https://element-hq.github.io/synapse/latest/index.html">Synapse</a> homeserver implementation written in Python 3. Dendrite, its second-generation homeserver implementation written in Go, is currently released in beta. Dendrite will provide more memory efficiency and reliability out-of-the-box, making it an excellent choice for running on a virtual instance.</p>
<p>Here&rsquo;s how to set up your own homeserver on AWS Lightsail with Dendrite. You can also <a href="https://github.com/matrix-org/dendrite">contribute to Dendrite today</a>.</p>
<h2 id="create-a-lightsail-instance">Create a Lightsail instance</h2>
<p>Spin up a new Lightsail instance on AWS with Debian as your operating system. It&rsquo;s a good idea to create a new per-instance key for use with SSH. You can do this by with the SSH key pair manager on the instance creation page. Don&rsquo;t forget to download your private key and <code>.gitignore</code> your secrets.</p>
<p>Click <strong>Create Instance.</strong> Wait for the status of your instance to change from <strong>Pending</strong> to <strong>Running</strong>, then click its name to see further information. You&rsquo;ll need the Public IP address.</p>
<p>To enable people including yourself to connect to the instance, go to the Networking tab and add a firewall rule for HTTPS. This will open <code>443</code> so you can connect over IPv4. You can also do this for IPv6.</p>
<h2 id="connect-dns">Connect DNS</h2>
<p>Give your instance a catchier address by <a href="https://www.jdoqocy.com/ds70r09608OQPPRVXSQPOQSRVVVVX" target="_top">buying a domain at Namecheap</a>
 and setting up DNS records.</p>
<ol>
<li>On your domain management page in the <strong>Nameservers</strong> section, choose <strong>Namecheap BasicDNS</strong>.</li>
<li>On the <strong>Advanced DNS</strong> tab, click <strong>Add New Record</strong>.</li>
</ol>
<p>Add an <code>A Record</code> to your Lightsail Public IP. You can use a subdomain if you want one, for example,</p>
<ul>
<li><strong>Type:</strong> <code>A Record</code></li>
<li><strong>Host:</strong> <code>matrix</code></li>
<li><strong>Value:</strong> <code>13.59.251.229</code></li>
</ul>
<p>This points <code>matrix.example.org</code> to your Lightsail instance.</p>
<h2 id="set-up-your-matrix-homeserver">Set up your Matrix homeserver</h2>
<p>Change permissions on the private key you downloaded:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>chmod <span style="color:#ae81ff">600</span> &lt;path/to/key&gt;
</span></span></code></pre></div><p>Then <a href="https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-ssh-using-terminal">SSH to your Public IP</a>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ssh -i &lt;path/to/key&gt; admin@&lt;public ip&gt;
</span></span></code></pre></div><p>Welcome to your instance! You can make it more interesting by downloading some packages you&rsquo;ll need for Dendrite. It&rsquo;s a good idea to use <code>apt</code> for this, but first you&rsquo;ll want to make sure you&rsquo;re getting the latest stuff.</p>
<p><em>Dec 2021 update: As the good people of Mastodon point out, you might like to ensure you&rsquo;re choosing the stable version for Debian. For instance, replace <code>buster</code> below with <a href="https://www.debian.org/releases/">what&rsquo;s &ldquo;stable&rdquo; at the moment</a>.</em></p>
<p>Change your <a href="https://wiki.debian.org/SourcesList">sources list</a> in order to get the newest version of Go:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo vim /etc/apt/sources.list
</span></span></code></pre></div><p>Delete everything except these two lines:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-vim" data-lang="vim"><span style="display:flex;"><span><span style="color:#a6e22e">deb</span> <span style="color:#a6e22e">http</span>:<span style="color:#e6db74">//</span><span style="color:#a6e22e">cdn</span>-<span style="color:#a6e22e">aws</span>.<span style="color:#a6e22e">deb</span>.<span style="color:#a6e22e">debian</span>.<span style="color:#a6e22e">org</span>/<span style="color:#a6e22e">debian</span> <span style="color:#a6e22e">buster</span> <span style="color:#a6e22e">main</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">deb</span>-<span style="color:#a6e22e">src</span> <span style="color:#a6e22e">http</span>:<span style="color:#e6db74">//</span><span style="color:#a6e22e">cdn</span>-<span style="color:#a6e22e">aws</span>.<span style="color:#a6e22e">deb</span>.<span style="color:#a6e22e">debian</span>.<span style="color:#a6e22e">org</span>/<span style="color:#a6e22e">debian</span> <span style="color:#a6e22e">buster</span> <span style="color:#a6e22e">main</span>
</span></span></code></pre></div><p>Then replace the distributions:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-vim" data-lang="vim"><span style="display:flex;"><span>:%<span style="color:#a6e22e">s</span><span style="color:#e6db74">/buster main/</span><span style="color:#a6e22e">testing</span> <span style="color:#a6e22e">main</span> <span style="color:#a6e22e">contrib</span> <span style="color:#a6e22e">non</span>-<span style="color:#a6e22e">free</span>/<span style="color:#a6e22e">g</span>
</span></span></code></pre></div><p>Run <code>sudo apt dist-upgrade</code>. If you&rsquo;re asked about modified configuration files, choose the option to &ldquo;keep the local version currently installed.&rdquo;</p>
<p>Once the upgrade is finished, restart your instance with <code>sudo shutdown -r now</code>.</p>
<p>Go make some coffee, then SSH back in. Get the packages you&rsquo;ll need with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo apt update
</span></span><span style="display:flex;"><span>sudo apt upgrade
</span></span><span style="display:flex;"><span>sudo apt install -y git golang nginx python3-certbot-nginx
</span></span></code></pre></div><p>You&rsquo;re ready to get Dendrite.</p>
<h2 id="get-dendrite">Get Dendrite</h2>
<p>Clone <a href="https://github.com/matrix-org/dendrite">Dendrite</a> and follow the <a href="https://github.com/matrix-org/dendrite#get-started">README instructions to get started</a>. You&rsquo;ll need to choose whether you want your Matrix instance to be federating. For simplicity, here&rsquo;s how to set up a non-federating deployment to start:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>git clone https://github.com/matrix-org/dendrite
</span></span><span style="display:flex;"><span>cd dendrite
</span></span><span style="display:flex;"><span>./build.sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generate a Matrix signing key for federation (required)</span>
</span></span><span style="display:flex;"><span>./bin/generate-keys --private-key matrix_key.pem
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generate a self-signed certificate (optional, but a valid TLS certificate is normally</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># needed for Matrix federation/clients to work properly!)</span>
</span></span><span style="display:flex;"><span>./bin/generate-keys --tls-cert server.crt --tls-key server.key
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Copy and modify the config file - you&#39;ll need to set a server name and paths to the keys</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># at the very least, along with setting up the database connection strings.</span>
</span></span><span style="display:flex;"><span>cp dendrite-config.yaml dendrite.yaml
</span></span></code></pre></div><h2 id="configure-dendrite">Configure Dendrite</h2>
<p>Modify the configuration file you just copied:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo vim dendrite.yaml
</span></span></code></pre></div><p>At minimum, set:</p>
<ul>
<li><code>server name</code> to your shiny new domain name, e.g. <code>matrix.example.org</code></li>
<li><code>disable_federation</code> to true or false</li>
<li><code>registration_disabled</code> to true or false</li>
</ul>
<p>You might like to read the <a href="https://github.com/matrix-org/dendrite/blob/master/docs/FAQ.md">Dendrite FAQ</a>.</p>
<h2 id="configure-nginx">Configure nginx</h2>
<p>Get the required packages if you didn&rsquo;t already install them above:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo apt install nginx python3-certbot-nginx
</span></span></code></pre></div><p>Create your site&rsquo;s configuration file under <code>sites-available</code> with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cd /etc/nginx/sites-available
</span></span><span style="display:flex;"><span>ln -s /etc/nginx/sites-available/&lt;sitename&gt; /etc/nginx/sites-enabled/&lt;sitename&gt;
</span></span><span style="display:flex;"><span>sudo cp default &lt;sitename&gt;
</span></span></code></pre></div><p>Edit your site configuration. Delete the <code>root</code> and <code>index</code> lines if you don&rsquo;t need them, and input your server name.</p>
<p>Your <code>location</code> block should look like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-nginx" data-lang="nginx"><span style="display:flex;"><span><span style="color:#66d9ef">location</span> <span style="color:#e6db74">/</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">proxy_pass</span> <span style="color:#e6db74">https://localhost:8448</span>;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Remove the <code>default</code> with: <code>sudo rm /etc/nginx/sites-enabled/default</code>.</p>
<h2 id="create-self-signed-certificates">Create self-signed certificates</h2>
<p>You can use <a href="https://certbot.eff.org/">Certbot</a> to generate self-signed certificates with <a href="https://letsencrypt.org/">Let&rsquo;s Encrypt</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo certbot --nginx -d &lt;your.site.address&gt;
</span></span></code></pre></div><p>If you don&rsquo;t want to give an email, add the <code>--register-unsafely-without-email</code> flag.</p>
<p>Test your configuration and restart nginx with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo nginx -t
</span></span><span style="display:flex;"><span>sudo systemctl restart nginx
</span></span></code></pre></div><p>Then start up your Matrix server.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># Build and run the server:</span>
</span></span><span style="display:flex;"><span>./bin/dendrite-monolith-server --tls-cert server.crt --tls-key server.key --config dendrite.yaml
</span></span></code></pre></div><p>Your Matrix server is up and running at your web address! If you disabled registration in your configuration, you may need to create a user. You can do this by running the included <code>dendrite/bin/createuser</code>.</p>
<p>You can log on to your new homeserver with any <a href="https://matrix.org/clients/">Matrix client</a>, or Matrix-capable applications like <a href="https://www.pidgin.im/plugins/?publisher=all&amp;query=&amp;type=">Pidgin with the Matrix plugin</a>.</p>
<h2 id="other-troubleshooting">Other troubleshooting</h2>
<h3 id="log-files">Log files</h3>
<p>If you get an error such as:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>... [github.com/matrix-org/dendrite/internal/log.go:155] setupFileHook
</span></span><span style="display:flex;"><span>  Couldn&#39;t create directory /var/log/dendrite: &#34;mkdir /var/log/dendrite: permission denied&#34;
</span></span></code></pre></div><p>You&rsquo;ll need to create a spot for your log files. Avoid the bad practice of running stuff with <code>sudo</code> whenever you can. Instead, create the necessary file with the right permissions:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo mkdir /var/log/dendrite
</span></span><span style="display:flex;"><span>sudo chown admin:admin /var/log/dendrite
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Build and run the server:</span>
</span></span><span style="display:flex;"><span>./bin/dendrite-monolith-server --tls-cert server.crt --tls-key server.key --config dendrite.yaml
</span></span></code></pre></div><h3 id="unable-to-decrypt">Unable to decrypt</h3>
<p>If you see: <code>Unable to decrypt: The sender's device has not sent us the keys for this message.</code> you may need to verify a user (sometimes yourself).</p>
<ol>
<li>In your client, open the user&rsquo;s profile. Click the lock icon if there is one, or otherwise look for a way to verify them.</li>
<li>You may be asked to see if some emojis presented to both users match if you&rsquo;re using certain clients like Element.</li>
<li>You can then re-request encryption keys for any sent messages.</li>
</ol>
<h2 id="set-up-your-own-matrix-server-today">Set up your own Matrix server today</h2>
<p>I hope you found this introduction to setting up your own Matrix homeserver to be helpful!</p>
]]></content></entry><entry><title type="html">Build your own serverless subscriber list with Go and AWS</title><link href="https://victoria.dev/archive/build-your-own-serverless-subscriber-list-with-go-and-aws/"/><id>https://victoria.dev/archive/build-your-own-serverless-subscriber-list-with-go-and-aws/</id><author><name>Victoria Drake</name></author><published>2020-11-10T04:52:50-05:00</published><updated>2020-11-10T04:52:50-05:00</updated><content type="html"><![CDATA[<p>You can now subscribe to my email list on <a href="/">victoria.dev</a>! Here&rsquo;s how I lovingly built a subscription sign up flow with email confirmation that doesn&rsquo;t suck. You can too.</p>
<h2 id="introducing-simple-subscribe">Introducing Simple Subscribe</h2>
<p>If you&rsquo;re interested in managing your own mailing list or newsletter, you can set up Simple Subscribe on your own AWS resources to collect email addresses. This open source API is written in Go, and runs on AWS Lambda. Visitors to your site can sign up to your list, which is stored in a DynamoDB table, ready to be queried or exported at your leisure.</p>
<p>When someone signs up, they&rsquo;ll receive an email asking them to confirm their subscription. This is sometimes called &ldquo;double opt-in,&rdquo; although I prefer the term &ldquo;verified.&rdquo; Simple Subscribe works on serverless infrastructure and uses an AWS Lambda to handle subscription, confirmation, and unsubscribe requests.</p>
<p>You can find the <a href="https://github.com/victoriadrake/simple-subscribe">Simple Subscribe project, with its fully open-source code, on GitHub</a>. I encourage you to pull up the code and follow along! In this post I&rsquo;ll share each build step, the thought process behind the API&rsquo;s single-responsibility functions, and security considerations for an AWS project like this one.</p>
<h2 id="building-a-verified-subscription-flow">Building a verified subscription flow</h2>
<p>A non-verified email sign up process is straightforward. Someone puts their email into a box on your website, then that email goes into your database. However, if I&rsquo;ve taught you anything about <a href="/blog/sql-injection-and-xss-what-white-hat-hackers-know-about-trusting-user-input/">not trusting user input</a>, the very idea of a non-verified sign up process should raise your hackles. Spam may be great when fried in a sandwich, but no fun when it&rsquo;s running up your AWS bill.</p>
<p>While you can use a strategy like a CAPTCHA or puzzle for is-it-a-human verification, these can create enough friction to turn away your potential subscribers. Instead, a confirmation email can help to ensure both address correctness and user sentience.</p>
<p>To build a subscription flow with email confirmation, create single-responsibility functions that satisfy each logical step. Those are:</p>
<ol>
<li>Accept an email address and record it.</li>
<li>Generate a token associated with that email address and record it.</li>
<li>Send a confirmation email to that email address with the token.</li>
<li>Accept a verification request that has both the email address and token.</li>
</ol>
<p>To achieve each of these goals, Simple Subscribe uses the <a href="https://docs.aws.amazon.com/sdk-for-go/api/">official AWS SDK for Go</a> to interact with DynamoDB and SES.</p>
<p>At each stage, consider what the data looks like and how you store it. This can help to handle conundrums like, &ldquo;What happens if someone tries to subscribe twice?&rdquo; or even <a href="/blog/if-you-want-to-build-a-treehouse-start-at-the-bottom/">threat-modeling</a> such as, &ldquo;What if someone subscribes with an email they don&rsquo;t own?&rdquo;</p>
<p>Ready? Let&rsquo;s break down each step and see how the magic happens.</p>
<h3 id="subscribing">Subscribing</h3>
<p>The subscription process begins with a humble web form, like the one on my site&rsquo;s main page. A form input with attributes <code>type=&quot;email&quot; required</code> helps with validation, <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input/email#Validation">thanks to the browser</a>. When submitted, the form sends a GET request to the Simple Subscribe subscription endpoint.</p>
<p>Simple Subscribe receives a GET request to this endpoint with a query string containing the intended subscriber&rsquo;s email. It then generates an <code>id</code> value and adds both <code>email</code> and <code>id</code> to your DynamoDB table.</p>
<p>The table item now looks like:</p>
<table>
  <thead>
      <tr>
          <th>email</th>
          <th>confirm</th>
          <th>id</th>
          <th>timestamp</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>subscriber@example.com</code></td>
          <td><em>false</em></td>
          <td><code>uuid-xxxxx</code></td>
          <td>2020-11-01 00:27:39</td>
      </tr>
  </tbody>
</table>
<p>The <code>confirm</code> column, which holds a boolean, indicates that the item is a subscription request that has not yet been confirmed. To verify an email address in the database, you&rsquo;ll need to find the correct item and change <code>confirm</code> to <code>true</code>.</p>
<p>As you work with your data, consider the goal of each manipulation and how you might compare an incoming request to existing data.</p>
<p>For example, if someone made a subsequent subscription request for the same email address, how would you handle it? You might say, &ldquo;Create a new line item with a new <code>id</code>,&rdquo; however, this might not be best strategy when your serverless application database is paid for by request volume.</p>
<p>Since <a href="https://aws.amazon.com/dynamodb/pricing/">DynamoDB Pricing</a> depends on how much data you read and write to your tables, it&rsquo;s advantageous to avoid piling on excess data.</p>
<p>With that in mind, it would be prudent to handle subscription requests for the same email by performing an update instead of adding a new line. Simple Subscribe actually uses the same function to either add or update a database item. This is typically referred to as, &ldquo;update or insert.&rdquo;</p>
<p>In a database like SQLite this is accomplished with the <a href="https://www.sqlite.org/lang_UPSERT.html">UPSERT syntax</a>. In the case of DynamoDB, you use an update operation. For the <a href="https://docs.aws.amazon.com/sdk-for-go/api/service/dynamodb/">Go SDK</a>, its syntax is <code>UpdateItem</code>.</p>
<p>When a duplicate subscription request is received, the database item is matched on the <code>email</code> only. If an existing line item is found, its <code>id</code> and <code>timestamp</code> are overridden, which updates the existing database record and avoids flooding your table with duplicate requests.</p>
<h3 id="verifying-email-addresses">Verifying email addresses</h3>
<p>After submitting the form, the intended subscriber then receives an email from SES containing a link. This link is built using the <code>email</code> and <code>id</code> from the table, and takes the format:</p>
<pre tabindex="0"><code class="language-url" data-lang="url">&lt;BASE_URL&gt;&lt;VERIFY_PATH&gt;/?email=subscriber@example.com&amp;id=uuid-xxxxx
</code></pre><p>In this set up, the <code>id</code> is a UUID that acts as a secret token. It provides an identifier that you can match that is sufficiently complex and hard to guess. This approach deters people from subscribing with email addresses they don&rsquo;t control.</p>
<p>Visiting the link sends a request to your verification endpoint with the <code>email</code> and <code>id</code> in the query string. This time, it&rsquo;s important to compare both the incoming <code>email</code> and <code>id</code> values to the database record. This verifies that the recipient of the confirmation email is initiating the request.</p>
<p>The verification endpoint ensures that these values match an item in your database, then performs another update operation to set <code>confirm</code> to <code>true</code>, and update the timestamp. The item now looks like:</p>
<table>
  <thead>
      <tr>
          <th>email</th>
          <th>confirm</th>
          <th>id</th>
          <th>timestamp</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>subscriber@example.com</code></td>
          <td><em>true</em></td>
          <td><code>uuid-xxxxx</code></td>
          <td>2020-11-01 00:37:39</td>
      </tr>
  </tbody>
</table>
<h3 id="querying-for-emails">Querying for emails</h3>
<p>You can now query your table to build your email list. Depending on your email sending solution, you might do this manually, with another Lambda, or even from the command line.</p>
<p>Since data for requested subscriptions (where <code>confirm</code> is <code>false</code>) is stored in the table alongside confirmed subscriptions, it&rsquo;s important to differentiate this data when querying for email addresses to send to. You&rsquo;ll want to ensure you only return emails where <code>confirm</code> is <code>true</code>.</p>
<h2 id="providing-unsubscribe-links">Providing unsubscribe links</h2>
<p>Similar to verifying an email address, Simple Subscribe uses <code>email</code> and <code>id</code> as arguments to the function that deletes an item from your DynamoDB table in order to unsubscribe an email address. To allow people to remove themselves from your list, you&rsquo;ll need to provide a URL in each email you send that includes their <code>email</code> and <code>id</code> as a query string to the unsubscribe endpoint. It would look something like:</p>
<pre tabindex="0"><code class="language-url" data-lang="url">&lt;BASE_URL&gt;&lt;UNSUBSCRIBE_PATH&gt;/?email=subscriber@example.com&amp;id=uuid-xxxxx
</code></pre><p>When the link is clicked, the query string is passed to the unsubscribe endpoint. If the provided <code>email</code> and <code>id</code> match a database item, that item will be deleted.</p>
<p>Proving a method for your subscribers to automatically remove themselves from your list, without any human intervention necessary, is part of an ethical and respectful philosophy towards handling the data that&rsquo;s been entrusted to you.</p>
<h2 id="caring-for-your-data">Caring for your data</h2>
<p>Once you decide to accept other people&rsquo;s data, it becomes your responsibility to care for it. This is applicable to everything you build. For Simple Subscribe, it means maintaining the security of your database, and periodically pruning your table.</p>
<p>In order to avoid retaining email addresses where <code>confirm</code> is <code>false</code> past a certain time frame, it would be a good idea to set up a cleaning function that runs on a regular schedule. This can be achieved manually, with an AWS Lambda function, or using the command line.</p>
<p>To clean up, find database items where <code>confirm</code> is <code>false</code> and <code>timestamp</code> is older than a particular point in time. Depending on your use case and request volumes, the frequency at which you choose to clean up will vary.</p>
<p>Also depending on your use case, you may wish to keep backups of your data. If you are particularly concerned about data integrity, you can explore <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/backuprestore_HowItWorks.html">On-Demand Backup</a> or <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/PointInTimeRecovery.html">Point-in-Time Recovery</a> for DynamoDB.</p>
<h2 id="build-your-independent-subscriber-base">Build your independent subscriber base</h2>
<p>Building your own subscriber list can be an empowering endeavor! Whether you intend to start a newsletter, send out notifications for new content, or want to create a community around your work, there&rsquo;s nothing more personal or direct than an email from me to you.</p>
<p>I encourage you to start building your subscriber base with Simple Subscribe today! Like most of my work, it&rsquo;s open source and free for your personal use. Dive into the code at <a href="https://github.com/victoriadrake/simple-subscribe">the GitHub repository</a> or learn more at <a href="https://simplesubscribe.org">SimpleSubscribe.org</a>.</p>
]]></content></entry><entry><title type="html">A cron job that could save you from a ransomware attack</title><link href="https://victoria.dev/archive/a-cron-job-that-could-save-you-from-a-ransomware-attack/"/><id>https://victoria.dev/archive/a-cron-job-that-could-save-you-from-a-ransomware-attack/</id><author><name>Victoria Drake</name></author><published>2019-11-13T08:27:31-04:00</published><updated>2019-11-13T08:27:31-04:00</updated><content type="html"><![CDATA[<p>It&rsquo;s 2019, and ransomware has become a thing.</p>
<p>Systems that interact with the public, like companies, educational institutions, and public services, are most susceptible. While delivery methods for ransomware vary from the physical realm to communication via social sites and email, all methods only require one person to make one mistake in order for ransomware to proliferate.</p>
<p>Ransomware, as you may have heard, is a malicious program that encrypts your files, rendering them unreadable and useless to you. It can include instructions for paying a ransom, usually by sending cryptocurrency, in order to obtain the decryption key. Successful ransomware attacks typically exploit vital, time-sensitive systems. Victims like public services and medical facilities are more likely to have poor or zero recovery processes, leaving governments or insurance providers to reward attackers with ransom payments.</p>
<p>Individuals, especially less-than-tech-savvy ones, are no less at risk. Ransomware can occlude personal documents and family photos that may only exist on one machine.</p>
<p>Thankfully, a fairly low-tech solution exists for rendering ransomware inept: back up your data!</p>
<p>You could achieve this with a straightforward system like plugging in an external hard drive and dragging files over once a day, but this method has a few hurdles. Manually transferring files may be slow or incomplete, and besides, you&rsquo;ll first have to remember to do it.</p>
<p>In my constant pursuit of automating all the things, there&rsquo;s one tool I often return to for its simplicity and reliability: <code>cron</code>. Cron does one thing, and does it well: it runs commands on a schedule.</p>
<p>I first used it a few months shy of three years ago (Have I really been blogging that long?!) to create <a href="/blog/how-i-created-custom-desktop-notifications-using-terminal-and-cron/">custom desktop notifications on Linux</a>. Using the crontab configuration file, which you can edit by running <code>crontab -e</code>, you can specify a schedule for running any commands you like. Here&rsquo;s what the scheduling syntax looks like, from the <a href="https://en.wikipedia.org/wiki/Cron">Wikipedia cron page</a>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># ┌───────────── minute (0 - 59)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># │ ┌───────────── hour (0 - 23)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># │ │ ┌───────────── day of the month (1 - 31)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># │ │ │ ┌───────────── month (1 - 12)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># │ │ │ │ ┌───────────── day of the week (0 - 6)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># │ │ │ │ │</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># │ │ │ │ │</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># │ │ │ │ │</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># * * * * * command to execute</span>
</span></span></code></pre></div><p>For example, a cron job that runs every day at 00:00 would look like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#ae81ff">0</span> <span style="color:#ae81ff">0</span> * * *
</span></span></code></pre></div><p>To run a job every twelve hours, the syntax is:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#ae81ff">0</span> */12 * * *
</span></span></code></pre></div><p>This <a href="https://crontab.guru/">great tool</a> can help you wrap your head around the cron scheduling syntax.</p>
<p>What&rsquo;s a scheduler have to do with backing up? By itself, not much. The simple beauty of cron is that it runs commands - any shell commands, and any scripts that you&rsquo;d normally run on the command line. As you may have gleaned from my other posts, I&rsquo;m of the strong opinion that you can do just about anything on the command line, including backing up your files. Options for storage in this area are plentiful, from near-to-free local and cloud options, as well as paid managed services too numerous to list. For CLI tooling, we have utilitarian classics like <code>rsync</code>, and CLI tools for specific cloud providers like AWS.</p>
<h2 id="backing-up-with-rsync">Backing up with <code>rsync</code></h2>
<p><a href="https://en.wikipedia.org/wiki/Rsync">The <code>rsync</code> utility</a> is a classic choice, and can back up your files to an external hard drive or remote server while making intelligent determinations about which files to update. It uses file size and modification times to recognize file changes, and then only transfers changed files, saving time and bandwidth.</p>
<p>The <a href="https://download.samba.org/pub/rsync/rsync.html"><code>rsync</code> syntax</a> can be a little nuanced; for example, a trailing forward slash will copy just the contents of the directory, instead of the directory itself. I found examples to be helpful in understanding the usage and syntax.</p>
<p>Here&rsquo;s one for backing up a local directory to a local destination, such as an external hard drive:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>rsync -a /home/user/directory /media/user/destination
</span></span></code></pre></div><p>The first argument is the source, and the second is the destination. Reversing these in the above example would copy files from the mounted drive to the local home directory.</p>
<p>The <code>a</code> flag for archive mode is one of <code>rsync</code>&rsquo;s superpowers. Equivalent to flags <code>-rlptgoD</code>, it:</p>
<ul>
<li>Syncs files recursively through directories (<code>r</code>);</li>
<li>Preserves symlinks (<code>l</code>), permissions (<code>p</code>), modification times (<code>t</code>), groups (<code>g</code>), and owner (<code>o</code>); and</li>
<li>Copies device and special files (<code>D</code>).</li>
</ul>
<p>Here&rsquo;s another example, this time for backing up the contents of a local directory to a directory on a remote server using SSH:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>rsync -avze ssh /home/user/directory/ user@remote.host.net:home/user/directory
</span></span></code></pre></div><p>The <code>v</code> flag turns on verbose output, which is helpful if you like realtime feedback on which files are being transferred. During large transfers, however, it can tend to slow things down. The <code>z</code> flag can help with that, as it indicates that files should be compressed during transfer.</p>
<p>The <code>e</code> flag, followed by <code>ssh</code>, tells <code>rsync</code> to use SSH according to the destination instructions provided in the final argument.</p>
<h2 id="backing-up-with-aws-cli">Backing up with AWS CLI</h2>
<p>Amazon Web Services offers a command line interface tool for doing just about everything with your AWS set up, including a straightforward <a href="https://docs.aws.amazon.com/ja_jp/cli/latest/reference/s3/sync.html"><code>s3 sync</code> command</a> for recursively copying new and updated files to your S3 storage buckets. As a storage method for back up data, S3 is a stable and inexpensive choice. You can even <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html">turn on versioning in your bucket</a>.</p>
<p>The <a href="https://docs.aws.amazon.com/ja_jp/cli/latest/reference/s3/index.html#directory-and-s3-prefix-operations">syntax for interacting with directories</a> is fairly straightforward, and you can directly indicate your S3 bucket as an <code>S3Uri</code> argument in the form of <code>s3://mybucket/mykey</code>. To back up a local directory to your S3 bucket, the command is:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>aws s3 sync /home/user/directory s3://mybucket
</span></span></code></pre></div><p>Similar to <code>rsync</code>, reversing the source and destination would download files from the S3 bucket.</p>
<p>The <code>sync</code> command is intuitive by default. It will guess the mime type of uploaded files, as well as include files discovered by following symlinks. A variety of options exist to control these and other defaults, even including flags to specify the server-side encryption to be used.</p>
<h2 id="setting-up-your-cronjob-back-up">Setting up your cronjob back up</h2>
<p>You can edit your machine&rsquo;s cron file by running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>crontab -e
</span></span></code></pre></div><p>Intuitive as it may be, it&rsquo;s worth mentioning that your back up commands will only run when your computer is turned on and the cron daemon is running. With this in mind, choose a schedule for your cronjob that aligns with times when your machine is powered on, and maybe not overloaded with other work.</p>
<p>To back up to an S3 bucket every day at 8AM, for example, you&rsquo;d put a line in your crontab that looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#ae81ff">0</span> <span style="color:#ae81ff">8</span> * * * aws s3 sync /home/user/directory s3://mybucket
</span></span></code></pre></div><p>If you&rsquo;re curious whether your cron job is currently running, find the PID of cron with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>pstree -ap | grep cron
</span></span></code></pre></div><p>Then run <code>pstree -ap &lt;PID&gt;</code>.</p>
<p>This rabbit hole goes deeper; a quick search can reveal different ways of organizing and scheduling cronjobs, or help you find different utilities to run cronjobs when your computer is asleep. To protect against the possibility of ransomware-affected files being transferred to your back up, incrementally separated archives are a good idea. In essence, however, this basic set up is all you really need to create a reliable, automatic back up system.</p>
<h2 id="dont-feed-the-trolls">Don&rsquo;t feed the trolls</h2>
<p>Humans are fallible; that&rsquo;s why cyberattacks work. The success of a ransomware attack depends on the victim having no choice but to pay up in order to return to business as usual. A highly accessible recent back up undermines attackers who depend on us being unprepared. By blowing away a system and restoring from yesterday&rsquo;s back up, we may lose a day of progress; ransomers, however, gain nothing at all.</p>
<p>For further resources on ransomware defense for users and organizations, check out <a href="https://www.us-cert.gov/Ransomware">CISA&rsquo;s advice on ransomware</a>.</p>
]]></content></entry><entry><title type="html">Migrating to the cloud but without screwing it up, or how to move house</title><link href="https://victoria.dev/archive/migrating-to-the-cloud-but-without-screwing-it-up-or-how-to-move-house/"/><id>https://victoria.dev/archive/migrating-to-the-cloud-but-without-screwing-it-up-or-how-to-move-house/</id><author><name>Victoria Drake</name></author><published>2019-09-23T08:03:12-04:00</published><updated>2019-09-23T08:03:12-04:00</updated><content type="html"><![CDATA[<p>For an application that&rsquo;s ready to scale, not using managed cloud architecture these days is like insisting on digging your own well for water. It&rsquo;s far more labour-intensive, requires buying all your own equipment, takes a lot more time, and there&rsquo;s a higher chance you&rsquo;re going to get it wrong because you don&rsquo;t personally have a whole lot of experience digging wells, anyway.</p>
<p>That said - let&rsquo;s just get this out of the way first - there is no cloud. It&rsquo;s just someone else&rsquo;s computer.</p>
<p>Of course, these days, cloud services go far beyond the utility we&rsquo;d expect from a single computer. Besides being able to quickly set up and utilize the kind of computing power that previously required a new office lease agreement to house, there are now a multitude of monitoring, management, and analysis tools at our giddy fingertips. While it&rsquo;s important to understand that the cloud isn&rsquo;t a better option in every case, for applications that can take advantage of it, we can do more, do it faster, and do it for less money than if we were to insist on building our own on-premises infrastructure.</p>
<p>That&rsquo;s all great, and easily said; moving to the cloud, however, can look from the outset like a pretty daunting task. How, exactly, do we go about shifting what may be years of on-premises data and built-up systems to <em>someone else&rsquo;s computer?</em> You know, without being able to see it, touch it, and without completely screwing up our stuff.</p>
<p>While it probably takes less work and money than setting up or maintaining the same architecture on-premise, it does take some work to move to the cloud initially. It&rsquo;s important that our application is prepared to migrate, and capable of using the benefits of cloud services once it gets there. To accomplish this, and a smooth transition, preparation is key. In fact, it&rsquo;s a whole lot like moving to a new house.</p>
<p>In this article, we&rsquo;ll take a high-level look at the general stages of taking an on-premise or self-hosted application and moving it to the cloud. This guide is meant to serve as a starting point for designing the appropriate process for your particular situation, and to enable you to better understand the cloud migration process. While cloud migration may not be the best choice for some applications - such as ones without scalable architecture or where very high computing resources are needed - a majority of modular and modern applications stand to benefit from a move to the cloud.</p>
<p>It&rsquo;s certainly possible, as I discovered at a recent event put on by <a href="https://aws.amazon.com/">Amazon Web Services</a> (AWS) Solutions Architects, to migrate smoothly and efficiently, with near-zero loss of availability to customers. I&rsquo;ll specifically reference some services provided by AWS, however, similar functionality can be found with other cloud providers. I&rsquo;ve found the offerings from AWS to be pleasantly modular in scope, which is why I use them myself and why they make good examples for discussing general concepts.</p>
<p>To have our move go as smoothly as possible, here are the things we&rsquo;ll want to consider:</p>
<ol>
<li>The type of move we&rsquo;re making;</li>
<li>The things we&rsquo;ll take, and the things we&rsquo;ll clean up;</li>
<li>How to choose the right type and size for the infrastructure we&rsquo;re moving into; and</li>
<li>How to do test runs to practice for the big day.</li>
</ol>
<h2 id="the-type-of-move-were-making">The type of move we&rsquo;re making</h2>
<p>While it&rsquo;s important to understand why we&rsquo;re moving our application to cloud services, we should also have an idea of what we&rsquo;d like it to look like when it gets there. There are three main ways to move to the cloud: re-host, re-platform, or re-factor.</p>
<h3 id="re-host">Re-host</h3>
<p>A re-host scenario is the the most straightforward type of move. It involves no change to the way our application is built or how it runs. For example, if we currently have Python code, use PostgreSQL, and serve our application with Apache, a re-host move would mean we use all the same components, combined in just the same way, only now they&rsquo;re in the cloud. It&rsquo;s a lot like moving into a new house that has the exact same floor plan as the current one. All the furniture goes into the same room it&rsquo;s in now, and it&rsquo;s going to feel pretty familiar when we get there.</p>
<p>The main draw of a re-host move is that it may offer the least amount of complication necessary in order to take advantage of going to the cloud. Scalable applications, for example, can gain the ability to automatically manage necessary application resources.</p>
<p>While re-hosting makes scaling more automatic, it&rsquo;s important to note that it won&rsquo;t in itself make an application scalable. If the application infrastructure is not organized in such a way that gives it the ability to scale, a re-factor may be necessary instead.</p>
<h3 id="re-platform">Re-platform</h3>
<p>If a component of our current application set up isn&rsquo;t working out well for us, we&rsquo;re probably going to want to re-platform. In this case, we&rsquo;re making a change to at least one component of our architecture; for example, switching our database from Oracle to MySQL on <a href="https://aws.amazon.com/rds/">Amazon Relational Database Service</a> (RDS).</p>
<p>Like moving from a small apartment in Tokyo to an equally small apartment in New York, a re-platform doesn&rsquo;t change the basic nature of our application, but does change its appearance and environment. In the database change example, we&rsquo;ll have all the same data, just organized or formatted a little differently. In most cases, we won&rsquo;t have to make these changes manually. A tool such as <a href="https://aws.amazon.com/dms/">Amazon Database Migration Service</a> (DMS) can help to seamlessly shift our data over to the new database.</p>
<p>We might re-platform in order to enable us to better meet a business demand in the future, such as scaling up, integrating with other technological components, or choosing a more modern technology stack.</p>
<h3 id="re-factor">Re-factor</h3>
<p>A move in which we re-factor our application is necessarily more complicated than our other options, however, it may provide the most overall benefit for companies or applications that have reason to make this type of move. As with code, refactoring is done when fundamental changes need to be made in order for our application to meet a business need. The specifics necessarily differ case-by-case, but typically involve changes to architectural components or how those components relate to one another. This type of move may also involve changing application code in order to optimize the application&rsquo;s performance in a cloud environment. We can think of it like moving out from our parent&rsquo;s basement in the suburbs and getting a nice townhouse in the city. There&rsquo;s no way we&rsquo;re taking that ancient hand-me-down sofa, so we&rsquo;ll need some new furniture, and for our neighbour&rsquo;s sake, probably window dressings.</p>
<p>Refactoring may enable us to modernize a dated application, or make it more efficient in general. With greater efficiency, we can better take advantage of services that cloud providers typically offer, like bursting resources or attaining deep analytical insight.</p>
<p>If a re-factor is necessary but time is scarce, it may be better to re-host or re-platform first, then re-factor later. That way, we&rsquo;ll have a job well done later instead of a hasty, botched migration (and more problems) sooner.</p>
<h2 id="what-to-take-and-what-to-clean-up">What to take, and what to clean up</h2>
<p>Over the years of living in one place, stuff tends to pile up unnoticed in nooks and crannies. When moving house, it&rsquo;s usually a great opportunity to sort everything out and decide what is useful enough to keep, and what should be discarded or given away. Moving to the cloud is a similarly great opportunity to do the same when it comes to our application.</p>
<p>While cloud storage is inexpensive nowadays, there may be some things that don&rsquo;t make sense to store any longer, or at least not keep stored with our primary application. If data cannot be discarded due to policy or regulations, we may choose a different storage class to house data that we don&rsquo;t expect to need anytime soon outside of our main application.</p>
<p>In the case of <a href="https://aws.amazon.com/s3/">Amazon&rsquo;s Simple Storage Service</a> (S3), we can choose to use different <a href="https://aws.amazon.com/s3/storage-classes/">storage classes</a> that accomplish this goal. While the data that our business relies on every day can take advantage of the Standard class 99.99% availability, data meant for long-term cold storage such as archival backups can be put into the Glacier class, which has longer retrieval time and lower cost.</p>
<h2 id="the-right-type-and-size">The right type and size</h2>
<p>Choosing the type and size of cloud infrastructure appropriate for our business is usually the part that can be the most confusing. How should we predict, in a new environment or for a growing company, the computing power we&rsquo;ll need?</p>
<p>Part of the beauty of not procuring hardware on our own is that won&rsquo;t have to make predictions like these. Using cloud storage and instances, expanding or scaling back resources can be done in a matter of minutes, sometimes seconds. With managed services, it can even be done automatically for us. With the proper support for scalability in our application, it&rsquo;s like having a magical house that instantly generates any type of room and amenity we need at that moment. The ability to continually ensure that we&rsquo;re using appropriate, cost-effective resources is at our fingertips, and often clearly visualized in charts and dashboards.</p>
<p>For applications new to the cloud, some leeway for experimentation may be necessary. While cloud services enables us to quickly spin up and try out different architectures, there&rsquo;s no guarantee that all of those set ups will work well for our application. For example, running a single instance may be <a href="http://einaregilsson.com/serverless-15-percent-slower-and-eight-times-more-expensive/">less expensive than going serverless</a>, but we&rsquo;d be hard pressed to know this until we tried it out.</p>
<p>As a starting point, we simply need enough storage and computing power to support the application as it is currently running, today. For example, in the case of storage, consider the size of the current database - the actual database data, not the total storage capacity of hardware on-premises. For a detailed cost exploration, AWS even offers a <a href="https://calculator.s3.amazonaws.com/index.html">Simple Monthly Calculator</a> with use case samples to help guide expectations.</p>
<h2 id="do-test-runs-before-the-big-day">Do test runs before the big day</h2>
<p>Running a trial cloud migration may be an odd concept, but it is an essential component to ensuring that the move goes as planned with minimal service interruption. Imagine the time and energy that would be saved in the moving house example if we could automate test runs! Invariably, some box or still-hung picture is forgotten and left out of the main truck, necessitating additional trips in other vehicles. With multiple chances to ensure we&rsquo;ve got it down pat, we minimize the possibility that our move causes any break in normal day-to-day business.</p>
<p>Generally, to do a test run, we create a duplicate version of our application. The more we can duplicate, the more thorough the test run will be, especially if our data is especially large. Though duplication may seem tedious, working with the actual components we intend to migrate is essential to ensuring the migration goes as planned. After all, if we only did a moving-house test run with one box, it wouldn&rsquo;t be very representative.</p>
<p>Test runs can help to validate our migration plan against any challenges we may encounter. These challenges might include:</p>
<ul>
<li>Downtime restrictions;</li>
<li>Encrypting data in transit and immediately when at rest on the target;</li>
<li>Schema conversion to a new target schema (the <a href="https://aws.amazon.com/dms/schema-conversion-tool/">AWS Schema Conversion Tool</a> can also help);</li>
<li>Access to databases, such as through firewalls or VPNs;</li>
<li>Developing a process to ensure that all the data successfully migrated, such as by using a hash function.</li>
</ul>
<p>Test runs also help to give us a more accurate picture of the overall time that a migration will take, as well as affording us the opportunity to fine-tune it. Factors that may affect the overall speed of a migration include:</p>
<ul>
<li>The sizes of the source and target instances;</li>
<li>Available bandwidth for moving data;</li>
<li>Schema configurations; and</li>
<li>Transaction pressure on the source, such as changes to the data and the volume of incoming transactions.</li>
</ul>
<p>Once the duplicate application has been migrated via one or more <a href="https://aws.amazon.com/cloud-data-migration/">options</a>, we test the heck out of the application that&rsquo;s now running in the cloud to ensure it performs as expected. Ideally, on the big day, we&rsquo;d follow this same general process to move up-to-date duplicate data, and then seamlessly point the &ldquo;real&rdquo; application or web address to the new location in the cloud. This means that our customers experience near-zero downtime; essentially, only the amount of time that the change in location-pointing would need to propagate to their device.</p>
<p>In the case of very large or complex applications with many components or many teams working together at the same time, a more gradual approach may be more appropriate than the &ldquo;Big Bang&rdquo; approach, and may help to mitigate risk of any interruptions. This means migrating in stages, component by component, and running tests between stages to ensure that all parts of the application are communicating with each other as expected.</p>
<h2 id="preparation-is-essential-to-a-smooth-migration">Preparation is essential to a smooth migration</h2>
<p>I hope this article has enabled a more practical understanding of how cloud migration can be achieved. With thorough preparation, it&rsquo;s possible to take advantage of all the cloud has to offer, with minimal hassle to get there.</p>
<p>My thanks to the AWS Solutions Architects who presented at Pop-Up Loft and shared their knowledge on these topics, in particular: Chandra Kapireddy, Stephen Moon, John Franklin, Michael Alpaugh, and Priyanka Mahankali.</p>
<p>One last nugget of wisdom, courtesy of John: &ldquo;Friends don&rsquo;t let friends use DMS to create schema objects.&rdquo;</p>
]]></content></entry><entry><title type="html">How to set up OpenVPN on AWS EC2 and fix DNS leaks on Ubuntu 18.04 LTS</title><link href="https://victoria.dev/archive/how-to-set-up-openvpn-on-aws-ec2-and-fix-dns-leaks-on-ubuntu-18.04-lts/"/><id>https://victoria.dev/archive/how-to-set-up-openvpn-on-aws-ec2-and-fix-dns-leaks-on-ubuntu-18.04-lts/</id><author><name>Victoria Drake</name></author><published>2019-08-26T09:01:23-04:00</published><updated>2019-08-26T09:01:23-04:00</updated><content type="html"><![CDATA[<p>There&rsquo;s no better way to strive for maximum privacy than a VPN service you control, configure, and maintain yourself. Here&rsquo;s a step-by-step tutorial for <a href="#set-up-openvpn-on-aws-ec2">setting up your own OpenVPN on AWS EC2</a>, and <a href="#what-a-dns-leak-looks-like">how to check for and fix DNS leaks</a>.</p>
<p>For a VPN that also blocks ads and trackers, you can <a href="/blog/set-up-a-pi-hole-vpn-on-an-aws-lightsail-instance/">set up a Pi-hole VPN on an AWS Lightsail instance</a> instead.</p>
<h2 id="set-up-openvpn-on-aws-ec2">Set up OpenVPN on AWS EC2</h2>
<p>This post will cover how to set up the <a href="https://aws.amazon.com/marketplace/pp/B00MI40CAE/">OpenVPN Access Server</a> product on AWS Marketplace, running on an <a href="https://aws.amazon.com/ec2/">Amazon EC2 instance</a>. Then, you&rsquo;ll look at how to fix a <a href="https://gitlab.gnome.org/GNOME/NetworkManager-openvpn/issues/10">known NetworkManager bug in Ubuntu 18.04 that might cause DNS leaks</a>. The whole process should take about fifteen minutes, so grab a ☕ and let&rsquo;s be configuration superheroes.</p>
<p><em>Note: IDs and IP addresses shown for demonstration in this tutorial are invalid.</em></p>
<h3 id="1-launch-the-openvpn-access-server-on-aws-marketplace">1. Launch the OpenVPN Access Server on AWS Marketplace</h3>
<p>The <a href="https://aws.amazon.com/marketplace/pp/B00MI40CAE">OpenVPN Access Server</a> is available on AWS Marketplace. The Bring Your Own License (BYOL) model doesn&rsquo;t actually require a license for up to two connected devices; to connect more clients, you can get <a href="https://aws.amazon.com/marketplace/seller-profile/ref=srh_res_product_vendor?ie=UTF8&amp;id=aac3a8a3-2823-483c-b5aa-60022894b89d">bundled billing</a> for five, ten, or twenty-five clients, or <a href="https://openvpn.net/access-server/pricing/">purchase a minimum of ten OpenVPN licenses a la carte</a> for $15/device/year. For most of us, the two free connected devices will suffice; and if using an EC2 Micro instance, your set up will be <a href="https://aws.amazon.com/free/">AWS Free Tier eligible</a> as well.</p>
<p>Start by clicking <strong>Continue to Subscribe</strong> for the <a href="https://aws.amazon.com/marketplace/pp/B00MI40CAE">OpenVPN Access Server</a>, which will bring you to a page that looks like this:</p>
<p><img src="1-subscribe.jpg#screenshot" alt="Subscription details page for OpenVPN Access Server"></p>
<p>Click <strong>Continue to Configuration</strong>.</p>
<p><img src="2-configure.jpg#screenshot" alt="Configure this software page for OpenVPN Access Server"></p>
<p>You may notice that the EC2 instance type in the right side bar (and consequently, the Monthly Estimate) isn&rsquo;t the one you want - that&rsquo;s okay, you can change it soon. Just ensure that the <strong>Region</strong> chosen is where you want the instance to be located. Generally, the closer it is to the physical location of your client (your laptop, in this case), the faster your VPN will be. Click <strong>Continue to Launch</strong>.</p>
<p><img src="3-launch.jpg#screenshot" alt="Launch this software page"></p>
<p>On this page, you&rsquo;ll change three things:</p>
<h4 id="1-the-ec2-instance-type">1. The EC2 Instance type</h4>
<p>Different types of EC2 (Elastic Compute Cloud) instances will offer you different levels of computing power. If you plan to use your instance for something more than just this VPN, you may want to choose something with higher memory or storage capacity, depending on how you plan to use it. You can view each instance offering on the <a href="https://aws.amazon.com/ec2/instance-types/">Amazon EC2 Instance Types page</a>.</p>
<p>For simple VPN use, the <code>t2.nano</code> or <code>t2.micro</code> instances are likely sufficient. Only the Micro instance is Free Tier eligible.</p>
<h4 id="2-the-security-group-settings">2. The Security Group settings</h4>
<p>A <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html">Security Group</a> is a profile, or collection of settings, that Amazon uses to control access to your instance. If you&rsquo;ve set up other AWS products before, you may already have some groups with their own rules defined. You should be careful to understand the reasons for your Security Group settings, as these define how public or private your instance is, and consequently, who has access to it.</p>
<p>If you click <strong>Create New Based on Seller Settings</strong>, the OpenVPN server defines some recommended settings for a default Security Group.</p>
<p><img src="4-security-group.jpg#screenshot" alt="Security group settings"></p>
<p>The default recommended settings are all <code>0.0.0.0/0</code> for TCP ports 22, 943, 443, and 945, and UDP port 1194. OpenVPN offers an <a href="https://openvpn.net/vpn-server-resources/amazon-web-services-ec2-byol-appliance-quick-start-guide/#Instance_Launch_Options">explanation of how the ports are used</a> on their website. With the default settings, all these ports are left open to support various features of the OpenVPN server. You may wish to restrict access to these ports to a specific IP address or block of addresses (like that of your own ISP) to increase the security of your instance. However, if your IP address frequently changes (like when you travel and connect to a different WiFi network), restricting the ports may not be as helpful as you hope.</p>
<p>In any case, your instance will require SSH keys to connect to, and the OpenVPN server will be password protected. Unless you have other specific security goals, it&rsquo;s fine to accept the default settings for now.</p>
<p>Let&rsquo;s give the Security Group a name and brief description, so you know what it&rsquo;s for. Then click <strong>Save</strong>.</p>
<h4 id="3-the-key-pair-settings">3. The Key Pair settings</h4>
<p>The aforementioned SSH keys are access credentials that you&rsquo;ll use to connect to your instance. You can <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html#having-ec2-create-your-key-pair">create a key pair</a> in this section, or you can choose a key pair you may already be using with AWS.</p>
<p><img src="5-keys.jpg#screenshot" alt="Key Pair Settings link"></p>
<p>To create a new set of access credentials, click <strong>Create a key pair in EC2</strong> to open a new window. Then, click the <strong>Create Key Pair</strong> blue button. Once you give your key pair a name, it will be created and the private key will automatically download to your machine. It&rsquo;s a file ending with the extension <code>.pem</code>. Store this key in a secure place on your computer. You&rsquo;ll need to refer to it when you connect to your new EC2 instance.</p>
<p>You can return to the previous window to select the key pair you just created. If it doesn&rsquo;t show up, hit the little &ldquo;refresh&rdquo; icon next to the drop-down. Once it&rsquo;s selected, hit the shiny yellow <strong>Launch</strong> button.</p>
<p>You should see a message like this:</p>
<p><img src="6-launched.jpg#screenshot" alt="Launch success message"></p>
<p>Great stuff! Now that your instance exists, let&rsquo;s make sure you can access it and start up your VPN. For a shortcut to the next step, click on the &ldquo;EC2 Console&rdquo; link in the success message.</p>
<h3 id="2-associate-an-elastic-ip">2. Associate an Elastic IP</h3>
<p>Amazon&rsquo;s <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html">Elastic IP Addresses</a> provides you with a public IPv4 address controlled by your account, unlike the public IP address tied to your EC2 instance. It&rsquo;s considered a best practice to create one and associate it with your VPN instance. If anything should go wrong with your instance, or if you want to use a new instance for your VPN in the future, the Elastic IP can be disassociated from the current instance and reassociated with your new one. This makes the transition seamless for your connected clients. Think of the Elastic IP like a web domain address that you register - you can point it at whatever you choose.</p>
<p>We can create a new Elastic IP address on the Amazon EC2 Console. If you clicked the link from the success message above, we&rsquo;re already there.</p>
<p><img src="7-ec2.jpg#screenshot" alt="EC2 console"></p>
<p>If you have more than one instance, take note of the Instance ID of the one you&rsquo;ve just launched.</p>
<p>In the left sidebar under <strong>Network &amp; Security</strong>, choose <strong>Elastic IPs</strong>. Then click the blue <strong>Allocate new address</strong> button.</p>
<p><img src="8-elasticip.jpg#screenshot" alt="Allocate new address page"></p>
<p>Choose <strong>Amazon Pool,</strong> then click <strong>Allocate</strong>.</p>
<p><img src="9-elasticip.jpg#screenshot" alt="Allocate elastic IP success message"></p>
<p>Success! Click <strong>Close</strong> to return to the Elastic IP console.</p>
<p><img src="10-associateip.jpg#screenshot" alt="Associate elastic IP"></p>
<p>Now that you have an Elastic IP, let&rsquo;s associate it with your instance. Select the IP address, then click <strong>Actions,</strong> and choose <strong>Associate address</strong>.</p>
<p><img src="11-associateip.jpg#screenshot" alt="Associate elastic IP with instance"></p>
<p>Ensure the <strong>Instance</strong> option is selected, then click the drop-down menu. You should see your EC2 instance ID there. Select it, then click <strong>Associate</strong>.</p>
<p><img src="12-associateip.jpg#screenshot" alt="Associate elastic IP success message"></p>
<p>Success! Now that you&rsquo;ll be able to access your VPN instance, let&rsquo;s get your VPN service up and running.</p>
<h3 id="3-initialize-openvpn-on-the-ec2-server">3. Initialize OpenVPN on the EC2 server</h3>
<p>First, you&rsquo;ll need to connect to the EC2 instance via your terminal. You&rsquo;ll use the private key you created earlier.</p>
<p>Open a new terminal window and navigate to the directory containing the private key <code>.pem</code> file. You&rsquo;ll need to set its permissions with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo chmod <span style="color:#ae81ff">400</span> &lt;name&gt;.pem
</span></span></code></pre></div><p>Be sure to substitute <code>&lt;name&gt;</code> with the name of your key.</p>
<p>This sets the file permissions to <code>-r--------</code> so that it can only be read by the user (you). It may help to protect the private key from read and write operations by other users, but more importantly, will prevent AWS from throwing an error when you try to connect to your instance.</p>
<p>We can now do just that by running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ssh -i &lt;name&gt;.pem openvpnas@&lt;elastic ip&gt;
</span></span></code></pre></div><p>The user <code>openvpnas</code> is set up by the OpenVPN Access Server to allow you to connect to your instance. Replace <code>&lt;elastic ip&gt;</code> with the Elastic IP address you just associated.</p>
<p>We may get a message saying that the authenticity of your host can&rsquo;t be established. As long as you&rsquo;ve typed the Elastic IP correctly, go ahead and answer <strong>yes</strong> to the prompt.</p>
<p>Upon the initial connection to the OpenVPN instance, a set up wizard called <strong>Initial Configuration Tool</strong> should automatically run. (If, for some reason, it doesn&rsquo;t, or you panic-mashed a button, you can restart it with <code>sudo ovpn-init –ec2</code>.) You&rsquo;ll be asked to accept the agreement, then the wizard will help to walk you through some configuration settings for your VPN server.</p>
<p>You may generally accept the default settings, however, there are a couple questions you may like to answer knowledgeably. They are:</p>
<p><strong>Should client traffic be routed by default through the VPN?</strong></p>
<p><strong>Should client DNS traffic be routed by default through the VPN?</strong></p>
<p>These answers depend on your privacy goals for your VPN.</p>
<p>When asked for your <strong>OpenVPN-AS license key</strong>, you can leave it blank to use the VPN with up to two clients. If you&rsquo;ve purchased a key, enter it here.</p>
<p>Once the configuration wizard finishes running, you should see the message &ldquo;Initial Configuration Complete!&rdquo; Before you move on, you should set a password for your server&rsquo;s administration account. To do this, run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo passwd openvpn
</span></span></code></pre></div><p>Then enter your chosen password twice. Now we&rsquo;re ready to get connected!</p>
<p>To close the SSH connection, type <code>exit</code>.</p>
<h3 id="4-connect-the-client-to-the-vpn">4. Connect the client to the VPN</h3>
<p>To connect your client (in this case, your laptop) to the VPN and start reaping the benefits, you&rsquo;ll need to do two things; first, obtain your connection profile; second, install the <code>openvpn</code> daemon.</p>
<h4 id="1-get-your-ovpn-connection-profile">1. Get your <code>.ovpn</code> connection profile</h4>
<p>You&rsquo;ll need to download a connection profile; this is like a personal configuration file with information, including keys, that the VPN server will need to allow your connection. You can do this by logging in with the password you just set at your Elastic IP address, port 943. This looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>https://&lt;elastic ip&gt;:943/
</span></span></code></pre></div><p>The <code>https</code> part is important; without it, the instance won&rsquo;t send any data.</p>
<p>When you go to this URL, you may see a page warning you that this site&rsquo;s certificate issuer is unknown or invalid. As long as you&rsquo;ve typed your Elastic IP correctly, it&rsquo;s safe to proceed. If you&rsquo;re using Firefox, click <strong>Advanced</strong>, and then <strong>Accept the Risk and Continue</strong>. In Chrome, click <strong>Advanced</strong>, then <strong>Proceed</strong> to the elastic IP.</p>
<p><img src="13-warning.jpg#screenshot" alt="Security warning page"></p>
<p>Log in with the username <code>openvpn</code> and the password you just set. You&rsquo;ll now be presented with a link to download your user-locked connection profile:</p>
<p><img src="14-profile.jpg#screenshot" alt="Connection profile download page"></p>
<p>When you click the link, a file named <code>client.ovpn</code> will download.</p>
<h4 id="2-install-and-start-openvpn-on-your-ubuntu-1804-client">2. Install and start <code>openvpn</code> on your Ubuntu 18.04 client</h4>
<p>The <code>openvpn</code> daemon will allow your client to connect to your VPN server. It can be installed through the default Ubuntu repositories. Run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo apt install openvpn
</span></span></code></pre></div><p>In order for OpenVPN to automatically start when you boot up your computer, you&rsquo;ll need to rename and move the connection profile file. I suggest using a <a href="https://en.wikipedia.org/wiki/Symbolic_link">symlink</a> to accomplish this, as it leaves your original file more easily accessible for editing, and allows you to store it in any directory you choose. You can create a symlink by running this command in the directory where your file is located:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo ln -s client.ovpn /etc/openvpn/&lt;name&gt;.conf
</span></span></code></pre></div><p>This creates a symbolic link for the connection profile in the appropriate folder for <code>systemd</code> to find it. The <code>&lt;name&gt;</code> can be anything. When the Linux kernel has booted, <code>systemd</code> is used to initialize the services and daemons that the user has set up to run; one of these will now be OpenVPN. Renaming the file with the extension <code>.conf</code> will let the <code>openvpn</code> daemon know to use it as your connection file.</p>
<p>For now, you can manually start and connect to OpenVPN by running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo openvpn --config client.ovpn
</span></span></code></pre></div><p>You&rsquo;ll be asked for a username and password, which will be the same credentials you used before. Once the service finishes starting up, you&rsquo;ll see &ldquo;Initialization Sequence Complete.&rdquo; If you now visit <a href="https://www.dnsleaktest.com/">the DNS leak test website</a>, you should see the Elastic IP and the location of your EC2 server. Yay!</p>
<p>If you&rsquo;re on a later version of Ubuntu, you may check for DNS leaks by clicking on one of the test buttons. If all the ISPs shown are Amazon and none are your own service provider&rsquo;s, congratulations! No leaks! You can move on to <a href="#3-set-up-openvpn-as-networkmanager-system-connection">Step 3 in the second section</a> below, after which, you&rsquo;ll be finished.</p>
<p>If you&rsquo;re using Ubuntu 18.04 LTS, however, we&rsquo;re not yet done.</p>
<h2 id="what-a-dns-leak-looks-like">What a DNS leak looks like</h2>
<p>Sites like <a href="https://dnsleaktest.com/">the DNS leak test website</a> can help you check your configuration and see if the Internet knows more about your location than you&rsquo;d like. On the main page you&rsquo;ll see a big hello, your IP address, and your location, so far as can be determined.</p>
<p>If you have a DNS leak, you can see what it looks like by clicking on one of the test buttons on the <a href="https://www.dnsleaktest.com/">the DNS leak test page</a>. When you do, you&rsquo;ll see not only your Amazon.com IP addresses, but also your own ISP and location.</p>
<p>You can also see the leak by running <code>systemd-resolve --status</code> in your terminal. Your results will contain two lines under different interfaces that both have entries for DNS Servers. It&rsquo;ll look something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>Link <span style="color:#ae81ff">7</span> <span style="color:#f92672">(</span>tun0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      Current Scopes: DNS
</span></span><span style="display:flex;"><span>       LLMNR setting: yes
</span></span><span style="display:flex;"><span>MulticastDNS setting: no
</span></span><span style="display:flex;"><span>      DNSSEC setting: no
</span></span><span style="display:flex;"><span>    DNSSEC supported: no
</span></span><span style="display:flex;"><span>         DNS Servers: 172.31.0.2
</span></span><span style="display:flex;"><span>          DNS Domain: ~.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Link <span style="color:#ae81ff">3</span> <span style="color:#f92672">(</span>wlp4s0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      Current Scopes: none
</span></span><span style="display:flex;"><span>       LLMNR setting: yes
</span></span><span style="display:flex;"><span>MulticastDNS setting: no
</span></span><span style="display:flex;"><span>      DNSSEC setting: no
</span></span><span style="display:flex;"><span>    DNSSEC supported: no
</span></span><span style="display:flex;"><span>         DNS Servers: 192.168.0.1
</span></span><span style="display:flex;"><span>          DNS Domain: ~.
</span></span></code></pre></div><p>The <a href="https://unix.stackexchange.com/questions/434916/how-to-fix-openvpn-dns-leak">DNS leak problem in Ubuntu 18.04</a> stems from Ubuntu&rsquo;s DNS resolver, <code>systemd-resolved</code>, failing to properly handle your OpenVPN configuration. In order to try and be a good, efficient DNS resolver, <code>systemd-resolved</code> will send DNS lookup requests in parallel to each interface that has a DNS server configuration, and then utilizes the fastest response. In your case, you only want to use your VPN&rsquo;s DNS servers. Sorry, <code>systemd-resolved</code>. You tried.</p>
<h2 id="how-to-fix-openvpn-dns-leak-on-ubuntu-1804">How to fix OpenVPN DNS leak on Ubuntu 18.04</h2>
<p>Luckily, there is a fix that you can implement. You&rsquo;ll need to install a few helpers from the Ubuntu repositories, update your configuration file, then set up OpenVPN using NetworkManager. Let&rsquo;s do it!</p>
<h3 id="1-install-some-helpers">1. Install some helpers</h3>
<p>To properly integrate OpenVPN with <code>systemd-resolved</code>, you&rsquo;ll need a bit more help. In a terminal, run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo apt install -y openvpn-systemd-resolved network-manager-openvpn network-manager-openvpn-gnome
</span></span></code></pre></div><p>This will install a helper script that integrates OpenVPN and <code>systemd-resolved</code>, a NetworkManager plugin for OpenVPN, and its GUI counterpart for GNOME desktop environment.</p>
<h3 id="2-add-dns-implementation-to-your-connection-profile">2. Add DNS implementation to your connection profile</h3>
<p>You&rsquo;ll need to edit the connection profile file you downloaded earlier. Since it&rsquo;s symbolically linked, you can accomplish this by changing the <code>.ovpn</code> file, wherever it&rsquo;s stored. Run <code>vim &lt;name&gt;.ovpn</code> to open it in Vim, then add the following lines at the bottom. Explanation in the comments:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># Allow OpenVPN to call user-defined scripts</span>
</span></span><span style="display:flex;"><span>script-security <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Tell systemd-resolved to send all DNS queries over the VPN</span>
</span></span><span style="display:flex;"><span>dhcp-option DOMAIN-ROUTE .
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Use the update-systemd-resolved script when TUN/TAP device is opened,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># and also run the script on restarts and before the TUN/TAP device is closed</span>
</span></span><span style="display:flex;"><span>up /etc/openvpn/update-systemd-resolved
</span></span><span style="display:flex;"><span>up-restart
</span></span><span style="display:flex;"><span>down /etc/openvpn/update-systemd-resolved
</span></span><span style="display:flex;"><span>down-pre
</span></span></code></pre></div><p>For the full list of OpenVPN options, see <a href="https://openvpn.net/community-resources/reference-manual-for-openvpn-2-1/">OpenVPN Scripting and Environment Variables</a>. You may also like <a href="https://en.wikipedia.org/wiki/TUN/TAP">more information about TUN/TAP</a>.</p>
<h3 id="3-set-up-openvpn-as-networkmanager-system-connection">3. Set up OpenVPN as NetworkManager system connection</h3>
<p>Use the GUI to set up your VPN with NetworkManager. Open up Network Settings, which should look something like this:</p>
<p><img src="15-networksettings.png#screenshot" alt="Network Settings window on Ubuntu 18.04"></p>
<p>Then click the plus sign (<strong>+</strong>) button. On the window that pops up, counterintuitively, choose <strong>Import from file&hellip;</strong> instead of the OpenVPN option.</p>
<p><img src="16-importvpn.jpg#screenshot" alt="Add VPN window"></p>
<p>Navigate to, and then select, your <code>.ovpn</code> file. You should now see something like this:</p>
<p><img src="17-vpnsettings.png#screenshot" alt="The filled VPN connection settings"></p>
<p>Add your username and password for the server (<code>openvpn</code> and the password you set in <a href="#3-initialize-openvpn-on-the-ec2-server">the first section&rsquo;s Step 3</a>), and your user key password (the same one again, if you&rsquo;ve followed this tutorial), then click the &ldquo;Add&rdquo; button.</p>
<h3 id="4-edit-your-openvpn-networkmanager-configuration">4. Edit your OpenVPN NetworkManager configuration</h3>
<p>Nearly there! Now that you&rsquo;ve added the VPN as a NetworkManager connection, you&rsquo;ll need to make a quick change to it. You can see a list of NetworkManager connections by running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ls -la /etc/NetworkManager/system-connections/*
</span></span></code></pre></div><p>The one for your VPN is probably called <code>openvpn</code>, so let&rsquo;s edit it by running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo vim /etc/NetworkManager/system-connections/openvpn
</span></span></code></pre></div><p>Under <code>[ipv4]</code>, you&rsquo;ll need to add the line <code>dns-priority=-42</code>. It should end up looking like this:</p>
<p><img src="18-connsettings.jpg#screenshot" alt="Connection settings for ipv4"></p>
<p>Setting a negative number is a workaround that prioritizes this DNS server. The actual number is arbitrary (<code>-1</code> should also work) but I like 42. ¯\_(ツ)_/¯</p>
<h3 id="5-restart-connect-profit">5. Restart, connect, profit</h3>
<p>In a terminal, run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo service network-manager restart
</span></span></code></pre></div><p>Then in the Network Settings, click the magic button that turns on the VPN:</p>
<p><img src="19-vpnon.jpg#screenshot" alt="Network Settings window"></p>
<p>Finally, visit <a href="https://www.dnsleaktest.com/">the DNS leak test website</a> and click on <strong>Extended test</strong> to verify the fix. If everything&rsquo;s working properly, you should now see a list containing only your VPN ISP.</p>
<p><img src="20-noleaks.png#screenshot" alt="Successful DNS leak test results"></p>
<p>And we&rsquo;re done! Congratulations on rolling your very own VPN server and stopping DNS leaks with OpenVPN. Enjoy surfing in (relative) privacy. Now your only worry at the local coffeeshop is who&rsquo;s watching you surf from the seat behind you.</p>
<p>If you enjoyed this post, there&rsquo;s a lot more where it came from! I write about computing, cybersecurity, and leading great technical teams. <a href="https://victoria.dev">Subscribe on victoria.dev</a> to see new articles first.</p>
]]></content></entry><entry><title type="html">Running a free Twitter bot on AWS Lambda</title><link href="https://victoria.dev/archive/running-a-free-twitter-bot-on-aws-lambda/"/><id>https://victoria.dev/archive/running-a-free-twitter-bot-on-aws-lambda/</id><author><name>Victoria Drake</name></author><published>2018-03-05T10:29:15-05:00</published><updated>2018-03-05T10:29:15-05:00</updated><content type="html"><![CDATA[<p>If you read <a href="/blog/about-time/">About time</a>, you&rsquo;ll know that I&rsquo;m a big believer in spending time now on building things that save time in the future. To this end I built a simple Twitter bot in Go that would occasionally post links to my articles and keep my account interesting even when I&rsquo;m too busy to use it. The tweets help drive traffic to my sites, and I don&rsquo;t have to lift a finger.</p>
<p>I ran the bot on an Amazon EC2 instance for about a month. My AWS usage has historically been pretty inexpensive (less than the price of a coffee in most of North America), so I was surprised when the little instance I was using racked up a bill 90% bigger than the month before. I don&rsquo;t think AWS is expensive, to be clear, but still&hellip; I&rsquo;m cheap. I want my Twitter bot, and I want it for less.</p>
<p>I&rsquo;d been meaning to explore AWS Lamda, and figured this was a good opportunity. Unlike an EC2 instance that is constantly running (and charging you for it), Lambda charges you per request and according to the duration of time your function takes to run. There&rsquo;s a free tier, too, and the first 1 million requests, plus a certain amount of compute time, are free. Roughly translated to running a Twitter bot that posts for you, say, twice a day, your monthly cost for using Lambda would total&hellip; carry the one&hellip; nothing. I&rsquo;ve been running my Lambda function for a couple weeks now, completely free.</p>
<p>When recently it came to me to take the reigns of the <a href="https://twitter.com/freeCodeCampTO">@freeCodeCampTO</a> Twitter, I decided to employ a similar strategy, and also use this opportunity to document the process for you, dear reader.</p>
<p>So if you&rsquo;re currently using a full-time running instance for a task that could be served by a cron job, this is the article for you. I&rsquo;ll cover how to write your function for Lambda, how to get it set up to run automatically, and as a sweet little bonus, a handy bash script that updates your function from the command line whenever you need to make a change. Let&rsquo;s do it!</p>
<h2 id="is-lambda-right-for-you">Is Lambda right for you</h2>
<p>When I wrote the code for my Twitter bot in Go, I intended to have it run on an AWS instance and borrowed heavily from <a href="https://github.com/campoy/justforfunc/tree/master/14-twitterbot">Francesc&rsquo;s awesome Just for Func episode</a>. Some time later I modified it to randomly choose an article from my RSS feeds and tweet the link, twice a day. I wanted to do something similar for the @freeCodeCampTO bot, and have it tweet an inspiring quote about programming every morning.</p>
<p>This is a good use case for Lambda because:</p>
<ul>
<li>The program should execute once</li>
<li>It runs on a regular schedule, using time as a trigger</li>
<li>It doesn&rsquo;t need to run constantly</li>
</ul>
<p>The important thing to keep in mind is that Lambda runs a function once in response to an event that you define. The most widely applicable trigger is a simple cron expression, but there are many other trigger events you can hook up. You can get an overview <a href="https://aws.amazon.com/lambda/">here</a>.</p>
<h2 id="write-a-lambda-function">Write a Lambda function</h2>
<p>I found this really straightforward to do in Go. First, grab the <a href="https://github.com/aws/aws-lambda-go">aws-lambda-go</a> library:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>go get github.com/aws/aws-lambda-go/lambda
</span></span></code></pre></div><p>Then make this your <code>func main()</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span> <span style="color:#a6e22e">lambda</span>.<span style="color:#a6e22e">Start</span>(<span style="color:#a6e22e">tweetFeed</span>)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Where <code>tweetFeed</code> is the name of the function that makes everything happen. While I won&rsquo;t go into writing the whole Twitter bot here, you can view my code <a href="https://gist.github.com/victoriadrake/7859dab68df87e28f40d6715d08383c7">on GitHub</a>.</p>
<h2 id="setting-up-aws-lambda">Setting up AWS Lambda</h2>
<p>I&rsquo;m assuming you already have an AWS account. If not, first things first here: <a href="https://aws.amazon.com/free">https://aws.amazon.com/free</a></p>
<h3 id="1-create-your-function">1. Create your function</h3>
<p>Find AWS Lambda in the list of services, then look for this shiny button:</p>
<p><img src="lambda-01.png#screenshot" alt="Create function"></p>
<p>We&rsquo;re going to author a function from scratch. Name your function, then under <strong>Runtime</strong> choose &ldquo;Go 1.x&rdquo;.</p>
<p>Under <strong>Role name</strong> write any name you like. It&rsquo;s a required field but irrelevant for this use case.</p>
<p>Click <strong>Create function.</strong></p>
<p><img src="lambda-02.png#screenshot" alt="Author from scratch"></p>
<h3 id="2-configure-your-function">2. Configure your function</h3>
<p>You&rsquo;ll see a screen for configuring your new function. Under <strong>Handler</strong> enter the name of your Go program.</p>
<p><img src="lambda-03.png#screenshot" alt="Configure your function"></p>
<p>If you scroll down, you&rsquo;ll see a spot to enter environment variables. This is a great place to enter the Twitter API tokens and secrets, using the variable names that your program expects. The AWS Lambda function will create the environment for you using the variables you provide here.</p>
<p><img src="lambda-04.png#screenshot" alt="Environment variables"></p>
<p>No further settings are necessary for this use case. Click <strong>Save</strong> at the top of the page.</p>
<h3 id="3-upload-your-code">3. Upload your code</h3>
<p>You can upload your function code as a zip file on the configuration screen. Since we&rsquo;re using Go, you&rsquo;ll want to <code>go build</code> first, then zip the resulting executable before uploading that to Lambda.</p>
<p>&hellip;Of course I&rsquo;m not going to do that manually every time I want to tweak my function. That&rsquo;s what <code>awscli</code> and this bash script is for!</p>
<p><code>update.sh</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>go build <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>zip fcc-tweet.zip fcc-tweet <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>rm fcc-tweet <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>aws lambda update-function-code --function-name fcc-tweet --zip-file fileb://fcc-tweet.zip <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>rm fcc-tweet.zip
</span></span></code></pre></div><p>Now whenever I make a tweak, I just run <code>bash update.sh</code>.</p>
<p>If you&rsquo;re not already using <a href="https://aws.amazon.com/cli/">AWS Command Line Interface</a>, do <code>pip install awscli</code> and thank me later. Find instructions for getting set up and configured in a few minutes <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html">here</a> under <strong>Quick Configuration</strong>.</p>
<h3 id="4-test-your-function">4. Test your function</h3>
<p>Wanna see it go? Of course you do! Click &ldquo;Configure test events&rdquo; in the dropdown at the top.</p>
<p><img src="lambda-05.png#screenshot" alt="Configure test events"></p>
<p>Since you&rsquo;ll use a time-based trigger for this function, you don&rsquo;t need to enter any code to define test events in the popup window. Simply write any name under <strong>Event name</strong> and empty the JSON in the field below. Then click <strong>Create</strong>.</p>
<p><img src="lambda-06.png#screenshot" alt="Configuring an empty test event"></p>
<p>Click <strong>Test</strong> at the top of the page, and if everything is working correctly you should see&hellip;</p>
<p><img src="lambda-07.png#screenshot" alt="Test success notification"></p>
<h3 id="5-set-up-cloudwatch-events">5. Set up CloudWatch Events</h3>
<p>To run our function as we would a cron job - as a regularly scheduled time-based event - we&rsquo;ll use CloudWatch. Click <strong>CloudWatch Events</strong> in the <strong>Designer</strong> sidebar.</p>
<p><img src="lambda-08.png#screenshot" alt="CloudWatch Events trigger"></p>
<p>Under <strong>Configure triggers</strong>, you&rsquo;ll create a new rule. Choose a descriptive name for your rule without spaces or punctuation, and ensure <strong>Schedule expression</strong> is selected. Then input the time you want your program to run as a <em>rate expression</em>, or cron expression.</p>
<p>A cron expression looks like this: <code>cron(0 12 * * ? *)</code></p>
<table>
  <thead>
      <tr>
          <th>Minutes</th>
          <th>Hours</th>
          <th>Month</th>
          <th>Day of week</th>
          <th>Year</th>
          <th>In English</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>0</td>
          <td>12</td>
          <td><code>*</code></td>
          <td>?</td>
          <td><code>*</code></td>
          <td>Run at noon (UTC) every day</td>
      </tr>
  </tbody>
</table>
<p>For more on how to write your cron expressions, read <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html">this.</a></p>
<p>If you want your program to run twice a day, say once at 10am and again at 3pm, you&rsquo;ll need to set two separate CloudWatch Events triggers and cron expression rules.</p>
<p>Click <strong>Add</strong>.</p>
<p><img src="lambda-09.png#screenshot" alt="Set cron expression rule"></p>
<h2 id="watch-it-go">Watch it go</h2>
<p>That&rsquo;s all you need to get your Lambda function up and running! Now you can sit back, relax, and do more important things than share your RSS links on Twitter.</p>
]]></content></entry><entry><title type="html">Moving to a new domain without breaking old links with AWS &amp;amp; Disqus</title><link href="https://victoria.dev/archive/moving-to-a-new-domain-without-breaking-old-links-with-aws-disqus/"/><id>https://victoria.dev/archive/moving-to-a-new-domain-without-breaking-old-links-with-aws-disqus/</id><author><name>Victoria Drake</name></author><published>2018-01-10T08:56:20-05:00</published><updated>2018-01-10T08:56:20-05:00</updated><content type="html"><![CDATA[<p>I started blogging about my nomadic travels last year, and so far the habit has stuck. Like all side projects, I won&rsquo;t typically invest heavily in setting up web properties before I can be reasonably certain that such an investment is worth my time or enjoyment. In other words: don&rsquo;t buy the domain until you&rsquo;ve proven to yourself that you&rsquo;ll stick with it!</p>
<p>After some months of regular posting I felt I was ready to commit (short courtship, I know, but we&rsquo;re all adults here) and I bought a dedicated domain, <a href="https://heronebag.com">herOneBag.com</a>.</p>
<p>Up until recently, my #NomadLyfe blog was just a subdirectory of my main personal site. Now it&rsquo;s all grown up and ready to strike out into the world alone! Here&rsquo;s the setup for the site:</p>
<ul>
<li>Static site in Amazon Web Services S3 bucket</li>
<li>Route 53 handling the DNS</li>
<li>CloudFront for distribution and a custom SSL certificate</li>
<li>Disqus for comments</li>
</ul>
<p>If you&rsquo;d like a walk-through for how to set up a new domain with this structure, it&rsquo;s over here: <a href="https://victoria.dev/verbose/aws-static-site/">Hosting your static site with AWS S3, Route 53, and CloudFront</a>. In this post, I&rsquo;ll just detail how I managed to move my blog to the new site without breaking the old links or losing any comments.</p>
<h2 id="preserve-old-links-with-redirection-rules">Preserve old links with redirection rules</h2>
<p>I wanted to avoid breaking links that have been posted around the web by forwarding visitors to the new URL. The change looks like this:</p>
<p>Old URL: <code>https://victoria.dev/meta/5-bag-lessons/</code></p>
<p>New URL: <code>https://heronebag.com/blog/5-bag-lessons/</code></p>
<p>You can see that the domain name as well as the subdirectory have changed, but the slug for the blog post remains the same. (I love static sites.)</p>
<p>To redirect links from the old site, we&rsquo;ll need to set redirection rules in the old site&rsquo;s S3 bucket. AWS provides a way to set up a conditional redirect. This is set in the &ldquo;Redirection rules&rdquo; section of your S3 bucket&rsquo;s properties, under &ldquo;Static website hosting.&rdquo; You can <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/how-to-page-redirect.html#advanced-conditional-redirects">find the documentation here.</a></p>
<p><img src="aws-redirect.png#screenshot" alt="Redirection rules placement"></p>
<p>There are a few examples given, but none that represent the redirect I want. In addition to changing the prefix of the object key, we&rsquo;re also changing the domain. The latter is achieved with the <code>&lt;HostName&gt;</code> tag.</p>
<p>To redirect requests for the old blog URL to the new top level domain, we&rsquo;ll use the code below.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;RoutingRules&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;RoutingRule&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;Condition&gt;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;KeyPrefixEquals&gt;</span>oldblog/<span style="color:#f92672">&lt;/KeyPrefixEquals&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;/Condition&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;Redirect&gt;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;HostName&gt;</span>newdomain.com<span style="color:#f92672">&lt;/HostName&gt;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;ReplaceKeyPrefixWith&gt;</span>newblog/<span style="color:#f92672">&lt;/ReplaceKeyPrefixWith&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;/Redirect&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;/RoutingRule&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;/RoutingRules&gt;</span>
</span></span></code></pre></div><p>This rule ensures that requests for <code>olddomain.com/oldblog/specific-blog-post</code> will redirect to <code>newdomain.com/newblog/specific-blog-post</code>.</p>
<h2 id="migrate-disqus-comments">Migrate Disqus comments</h2>
<p>Disqus provides a tool for migrating the comment threads from your old blog site to the new one. You can find it in your Disqus admin tools at <code>your-short-name.disqus.com/admin/discussions/migrate/</code>.</p>
<p>To migrate posts from the old blog address to the new one, we&rsquo;ll use the URL mapper tool. Click &ldquo;Start URL mapper,&rdquo; then &ldquo;you can download a CSV here.&rdquo;</p>
<p><img src="aws-disqus.png#screenshot" alt="URL mapping for Disqus."></p>
<p>Disqus has decent instructions for how this tool works, and you can <a href="https://help.disqus.com/customer/en/portal/articles/912757-url-mapper">read them here.</a> Basically, you&rsquo;ll input the new blog URLs into the second column of the CSV file you downloaded, then pass it back to Disqus to process. If you&rsquo;re using a program to edit the CSV, be sure to save the resulting file in CSV format.</p>
<p>Unless you have a bazillion URLs, the tool works pretty quickly, and you&rsquo;ll get an email when it&rsquo;s finished. Don&rsquo;t forget to update the name of your site in the Disqus admin, too.</p>
<h2 id="transfer-other-settings">Transfer other settings</h2>
<p>Update links in your social profiles and any other sites you may have around the web. If you&rsquo;re using other services attached to your website like Google Analytics or IFTTT, don&rsquo;t forget to update those details too!</p>
]]></content></entry><entry><title type="html">Hosting your static site with AWS S3, Route 53, and CloudFront</title><link href="https://victoria.dev/archive/hosting-your-static-site-with-aws-s3-route-53-and-cloudfront/"/><id>https://victoria.dev/archive/hosting-your-static-site-with-aws-s3-route-53-and-cloudfront/</id><author><name>Victoria Drake</name></author><published>2017-12-13T20:46:12-05:00</published><updated>2020-11-14T20:46:12-05:00</updated><content type="html"><![CDATA[<p>Some time ago I decided to stop freeloading on GitHub pages and move one of my sites to Amazon Web Services (AWS). It turns out that I&rsquo;m still mostly freeloading (yay free tier) so it amounted to a learning experience. Here are the components that let me host and serve the site at my custom domain with HTTPS.</p>
<ul>
<li>Static site in Amazon Web Services S3 bucket</li>
<li>Route 53 handling the DNS</li>
<li>CloudFront for distribution and a custom SSL certificate</li>
</ul>
<p>I set all that up most of a year ago. At the time, I found the AWS documentation to be rather fragmented and inconvenient to follow - it was hard to find what you were looking for without knowing what a specific setting might be called, or where it was, or if it existed at all. When I recently set up a new site and stumbled through this process again, I didn&rsquo;t find it any easier. Hopefully this post can help to collect the relevant information into a more easily followed process and serve as an accompanying guide to save future me (and you) some time.</p>
<p>Rather than replace existing documentation, this post is meant to supplement it. Think of me as your cool tech-savvy friend on the phone with you at 4am, troubleshooting your website. (Please don&rsquo;t actually call me at 4am.) I&rsquo;ll walk through the set up while providing links for the documentation that was ultimately helpful (mostly so I can find it again later&hellip;).</p>
<h2 id="hosting-a-static-site-with-amazon-s3-and-a-custom-domain">Hosting a static site with Amazon S3 and a custom domain</h2>
<p>If you&rsquo;re starting from scratch, you&rsquo;ll need an AWS account. It behooves you to get one, even if you don&rsquo;t like paying for services - there&rsquo;s a free tier that will cover most of the experimental stuff you&rsquo;re going to want to do in the first year, and even the things I do pay for cost me less than a dollar a month. You can sign up at <a href="https://aws.amazon.com/free">https://aws.amazon.com/free</a>.</p>
<p>Getting your static site hosted and available at your custom domain is your first mission, should you choose to accept it. <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html">Your instructions are here.</a></p>
<p>Creating the buckets for site hosting on S3 is the most straightforward part of this process in my opinion, and the AWS documentation walkthrough covers what you&rsquo;ll need to do quite well. It gets a little unclear around <em>Step 3: Create and Configure Amazon Route 53 Hosted Zone</em>, so come back and read on once you&rsquo;ve reached that point. I&rsquo;ll make some tea in the meantime.</p>
<p>&hellip; 🎶 🎵</p>
<p>Ready? Cool. See, I&rsquo;m here for you.</p>
<h2 id="set-up-route-53">Set up Route 53</h2>
<p>The majority of the work in this section amounts to creating the correct record sets for your custom domain. If you&rsquo;re already familiar with how record sets work, the documentation is a bit of a slog. Here&rsquo;s how it should look when you&rsquo;re finished:</p>
<p><img src="aws-recordsets.png#screenshot" alt="Route 53 record sets."></p>
<p>The &ldquo;NS&rdquo; and &ldquo;SOA&rdquo; records are created automatically for you. The only records you need to create are the &ldquo;A&rdquo; records.</p>
<p>Hop over to Route 53 and follow <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/MigratingDNS.html">this walkthrough</a> to create a &ldquo;hosted zone.&rdquo; The value of the <strong>NS</strong> (Name Servers) records are what you&rsquo;ll have to provide to your domain name registrar. Your registrar is wherever you bought your custom domain, such as this super subtle <a href="https://www.jdoqocy.com/ds70r09608OQPPRVXSQPOQSRVVVVX" target="_top">Namecheap.com affiliate link</a>
 right here. (Thanks for your support! 😊)</p>
<p>If you created two buckets in the first section (one for <code>yourdomain.com</code> and one for <code>www.yourdomain.com</code>), you&rsquo;ll need two separate A records in Route 53. Initially, these have the value of the endpoints for your matching S3 buckets (looks like <code>s3-website.us-east-2.amazonaws.com</code>). Later, you&rsquo;ll change them to your CloudFront domain name.</p>
<p>If you went with Namecheap as your registrar, <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html#root-domain-walkthrough-update-ns-record">Step 4</a> looks like this:</p>
<p><img src="aws-namecheapdns.png#screenshot" alt="Namecheap&rsquo;s Custom DNS settings."></p>
<p>Waiting is the hardest part&hellip; I&rsquo;ve gotten into the habit of working on another project or setting up the DNS change before going to bed so that changes have time to propagate without me feeling like I need to fiddle with it. ^^;</p>
<p>When the transfer&rsquo;s ready, you&rsquo;ll see your site at <code>http://yourdomain.com</code>. Next, you&rsquo;ll want to set up CloudFront so that becomes <code>https://yourdomain.com</code>.</p>
<h2 id="set-up-cloudfront-and-ssl">Set up CloudFront and SSL</h2>
<p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-cloudfront-walkthrough.html">Here are the instructions for setting up CloudFront.</a> There are a few important points to make sure you don&rsquo;t miss on the &ldquo;Create Distribution&rdquo; page:</p>
<ul>
<li><strong>Origin Domain Name:</strong> Make sure to use your S3 bucket endpoint, and not select the bucket from the dropdown menu that appears.</li>
<li><strong>Viewer Protocol Policy:</strong> If you want requests for <code>http://yourdomain.com</code> to always result in <code>https://yourdomain.com</code>, choose &ldquo;Redirect HTTP to HTTPS.&rdquo;</li>
<li><strong>Alternate Domain Names:</strong> Enter <code>yourdomain.com</code> and <code>www.yourdomain.com</code> on separate lines.</li>
<li><strong>SSL Certificate:</strong> See below.</li>
<li><strong>Default Root Object:</strong> Enter the name of the html file that should be returned when your users go to <code>https://yourdomain.com</code>. This is usually &ldquo;index.html&rdquo;.</li>
</ul>
<h3 id="ssl-certificate">SSL Certificate</h3>
<p>To show your content with HTTPS at your custom domain, you&rsquo;ll need to choose &ldquo;Custom SSL Certificate.&rdquo; You can easily get an SSL Certificate with AWS Certificate Manager. Click on &ldquo;Request or Import a Certificate with ACM&rdquo; to get started in a new window.</p>
<p><a href="http://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request.html">Here are instructions for setting up a certificate.</a> I don&rsquo;t think they&rsquo;re very good, personally. Don&rsquo;t worry, I got you.</p>
<p>To account for &ldquo;<a href="https://www.yourdomain.com">www.yourdomain.com</a>&rdquo; as well as any subdomains, you&rsquo;ll want to add two domain names to the certificate, like so:</p>
<p><img src="aws-acmdomains.png#screenshot" alt="Adding domain names to ACM."></p>
<p>Click &ldquo;Next.&rdquo; You&rsquo;ll be asked to choose a validation method. Choose &ldquo;DNS validation&rdquo; and click &ldquo;Review.&rdquo; If everything is as it should be, click &ldquo;Confirm and request.&rdquo;</p>
<p>You&rsquo;ll see a page, &ldquo;Validation&rdquo; that looks like this. You&rsquo;ll have to click the little arrow next to both domain names to get the important information to show:</p>
<p><img src="aws-acmvalidation.png#screenshot" alt="Validation instructions for ACM."></p>
<p>Under both domain names, click the button for &ldquo;Create record in Route 53.&rdquo; This will automatically create a CNAME record set in Route 53 with the given values, which ACM will then check in order to validate that you own those domains. You could create the records manually, if you wanted to for some reason. I don&rsquo;t know, maybe you&rsquo;re killing time. ¯\_(ツ)_/¯</p>
<p>Click &ldquo;Continue.&rdquo; You&rsquo;ll see a console that looks like this:</p>
<p><img src="aws-acmcertificates.png#screenshot" alt="List of certificates you own."></p>
<p>It may take some time for the validation to complete, at which point the &ldquo;Pending validation&rdquo; status will change to &ldquo;Issued.&rdquo; Again with the waiting. You can close this window to return to the CloudFront set up. Once the certificate is validated, you&rsquo;ll see it in the dropdown menu under &ldquo;Custom SSL Certificate.&rdquo; You can click &ldquo;Create Distribution&rdquo; to finish setting up CloudFront.</p>
<p>In your CloudFront Distributions console, you&rsquo;ll see &ldquo;In Progress&rdquo; until AWS has done its thing. Once it&rsquo;s done, it&rsquo;ll change to &ldquo;Deployed.&rdquo;</p>
<h3 id="one-last-thing">One last thing</h3>
<p>Return to your <a href="https://console.aws.amazon.com/route53/">Route 53 console</a> and click on &ldquo;Hosted zones&rdquo; in the sidebar, then your domain name from the list. For both A records, change the &ldquo;Alias Target&rdquo; from the S3 endpoint to your CloudFront distribution domain, which should look something like <code>dj4p1rv6mvubz.cloudfront.net</code>. It appears in the dropdown after you clear the field.</p>
<h2 id="youre-done">You&rsquo;re done</h2>
<p>Well, usually. If you navigate to your new HTTPS domain and don&rsquo;t see your beautiful new site where it should be, here are some things you can do:</p>
<ol>
<li>Check S3 bucket policy - ensure that the bucket for <code>yourdomain.com</code> in the S3 console shows &ldquo;Public&rdquo; in the &ldquo;Access&rdquo; column.</li>
<li>Check S3 bucket index document - In the &ldquo;metadata&rdquo; tab for the bucket, then &ldquo;Static website hosting&rdquo;. Usually &ldquo;index.html&rdquo;.</li>
<li>Check CloudFront Origin - the &ldquo;Origin&rdquo; column in the CloudFront Console should show the S3 bucket&rsquo;s endpoint (<code>s3-website.us-east-2.amazonaws.com</code>), not the bucket name (<code>yourdomain.com.s3.amazonaws.com</code>).</li>
<li>Check CloudFront Default Root Object - clicking on the distribution name should take you to a details page that shows &ldquo;Default Root Object&rdquo; in the list with the value that you set, usually &ldquo;index.html&rdquo;.</li>
<li>Wait. Sometimes changes take up to 48hrs to propagate. ¯\_(ツ)_/¯</li>
</ol>
<p>I hope that helps you get set up with your new static site on AWS! If you found this post helpful, there&rsquo;s a lot more where this came from. You can <a href="/">subscribe to victoria.dev</a> to see new posts first!</p>
]]></content></entry></feed>